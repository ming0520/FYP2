{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os system processing library\n",
    "import os\n",
    "import io\n",
    "import subprocess\n",
    "import shutil\n",
    "import random\n",
    "import json\n",
    "from glob import glob\n",
    "from shutil import move, rmtree, copyfile\n",
    "\n",
    "# mathematic operation\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# audio related\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import librosa.display\n",
    "# from google.cloud import speech\n",
    "\n",
    "# display libary\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "# machine learning libary\n",
    "# from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras as keras\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "# confussion matrix\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "# developed library\n",
    "import importlib\n",
    "import Timecode\n",
    "importlib.reload(Timecode)\n",
    "from Timecode import Timecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtraction:\n",
    "    def __init__(self, n_mels=128):\n",
    "        self.n_mels = n_mels\n",
    "        self.y = None\n",
    "        self.sr = 11025\n",
    "        self.S = None\n",
    "        self.log_S = None\n",
    "        self.mfcc = None\n",
    "        self.delta_mfcc = None\n",
    "        self.delta2_mfcc = None\n",
    "        self.M = None\n",
    "        self.rmse = None\n",
    "        self.foldername = None\n",
    "        self.filename=None\n",
    "    \n",
    "    def loadFile(self, foldernname):\n",
    "        self.foldernname=foldernname\n",
    "        self.y, self.sr = librosa.load(foldernname)\n",
    "#         logger.debug('File loaded: %s', foldernname)\n",
    "    \n",
    "    def load_y_sr(self, y, sr):\n",
    "        self.y = y\n",
    "        self.sr = sr\n",
    "    \n",
    "    def melspectrogram(self):\n",
    "        self.S = librosa.feature.melspectrogram(self.y, sr=self.sr, n_mels=self.n_mels)\n",
    "        self.log_S = librosa.amplitude_to_db(self.S)\n",
    "    \n",
    "    def plotmelspectrogram(self, save=True):\n",
    "        fig = plt.figure(figsize=(12, 4))\n",
    "        librosa.display.specshow(self.log_S, sr=self.sr, x_axis='time', y_axis='mel')\n",
    "        plt.title(f'mel Power Spectrogram ({self.filename})')\n",
    "        plt.colorbar(format='%+02.0f dB')\n",
    "        plt.tight_layout()\n",
    "        if not os.path.exists('mel'):\n",
    "            os.mkdir('mel')\n",
    "        if save:\n",
    "            fig.savefig(f'./mel/{self.filename}-mel.png', dpi=fig.dpi)\n",
    "            print(f'Saved to ./mel/{self.filename}-mel.png')\n",
    "            plt.close('all')\n",
    "\n",
    "    def extractmfcc(self, n_mfcc=13):\n",
    "        self.mfcc = librosa.feature.mfcc(S=self.log_S, n_mfcc=n_mfcc)\n",
    "        self.delta_mfcc = librosa.feature.delta(self.mfcc,mode='nearest')\n",
    "        self.delta2_mfcc = librosa.feature.delta(self.mfcc, order=2,mode='nearest')\n",
    "        self.M = np.vstack([self.mfcc, self.delta_mfcc, self.delta2_mfcc])\n",
    "    \n",
    "    def plotmfcc(self,save=False):\n",
    "        fig = plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(3, 1, 1)\n",
    "        librosa.display.specshow(self.mfcc)\n",
    "        plt.title(f'mel Power Spectrogram ({self.filename})')\n",
    "        plt.ylabel('MFCC')\n",
    "        plt.colorbar()\n",
    "        \n",
    "        plt.subplot(3, 1, 2)\n",
    "        librosa.display.specshow(self.delta_mfcc)\n",
    "        plt.title(f'mel Power Spectrogram ({self.filename})')\n",
    "        plt.ylabel('MFCC-$\\Delta$')\n",
    "        plt.colorbar()\n",
    "        \n",
    "        plt.subplot(3, 1, 3)\n",
    "        librosa.display.specshow(self.delta2_mfcc, sr=self.sr, x_axis='time')\n",
    "        plt.title(f'mel Power Spectrogram ({self.filename})')\n",
    "        plt.ylabel('MFCC-$\\Delta^2$')\n",
    "        plt.colorbar()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        if not os.path.exists('mfcc'):\n",
    "            os.mkdir('mfcc')\n",
    "        if save:\n",
    "            fig.savefig(f'./mfcc/{self.filename}-mfcc.png', dpi=fig.dpi)\n",
    "            print(f'Saved to ./mfcc/{self.filename}-mfcc.png')\n",
    "            plt.close('all')\n",
    "\n",
    "    def extractrmse(self):\n",
    "        self.rmse = librosa.feature.rms(y=self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self,):\n",
    "        self.X = np.empty(shape=(0,80))\n",
    "        self.Y = np.empty(shape=(0,2))\n",
    "        self.DATASET = None\n",
    "        self.PATH_ARRAY = []\n",
    "        self.failed_file = []\n",
    "        self.unexpected_label = []\n",
    "        self.processed_counter = 0\n",
    "        # self.TRACK_DURATION\n",
    "        # self.SAMPLES_PER_TRACK\n",
    "        print(\"Object created!\")\n",
    "\n",
    "    def create_dataset(self,dataset_path,output_path):\n",
    "        self.DATASET_PATH = dataset_path\n",
    "        self.OUTPUT_PATH = output_path\n",
    "        self.__process_dataset()\n",
    "        self.__write_to_file()\n",
    "        \n",
    "    def get_feature_by_audio(self,y,sr):\n",
    "          #exctract mfcc\n",
    "        try:\n",
    "            features = FeatureExtraction()\n",
    "            features.load_y_sr(y,sr)\n",
    "            features.melspectrogram()\n",
    "            features.extractmfcc()\n",
    "            features.extractrmse()\n",
    "        except ValueError:\n",
    "            self.failed_file.append(file_path)\n",
    "\n",
    "        feature_vector = []\n",
    "\n",
    "        for feature in features.mfcc:\n",
    "            feature_vector.append(np.mean(feature))\n",
    "            feature_vector.append(np.var(feature))\n",
    "\n",
    "        for feature in features.delta_mfcc:\n",
    "            feature_vector.append(np.mean(feature))\n",
    "            feature_vector.append(np.var(feature))\n",
    "\n",
    "        for feature in features.delta2_mfcc:\n",
    "            feature_vector.append(np.mean(feature))\n",
    "            feature_vector.append(np.var(feature))\n",
    "\n",
    "        feature_vector.append(np.mean(features.rmse))\n",
    "        feature_vector.append(np.var(features.rmse))\n",
    "\n",
    "        # self.X = np.vstack((self.X,[feature_vector])) \n",
    "        return feature_vector\n",
    "        \n",
    "    def get_feature_by_file(self,audio):\n",
    "        print(\"Extacting feature:\", audio)\n",
    "          #exctract mfcc\n",
    "        try:\n",
    "            features = FeatureExtraction()\n",
    "            features.loadFile(audio)\n",
    "            features.melspectrogram()\n",
    "            features.extractmfcc()\n",
    "            features.extractrmse()\n",
    "        except ValueError:\n",
    "            self.failed_file.apppend(file_path)\n",
    "\n",
    "        feature_vector = []\n",
    "\n",
    "        for feature in features.mfcc:\n",
    "            feature_vector.append(np.mean(feature))\n",
    "            feature_vector.append(np.var(feature))\n",
    "\n",
    "        for feature in features.delta_mfcc:\n",
    "            feature_vector.append(np.mean(feature))\n",
    "            feature_vector.append(np.var(feature))\n",
    "\n",
    "        for feature in features.delta2_mfcc:\n",
    "            feature_vector.append(np.mean(feature))\n",
    "            feature_vector.append(np.var(feature))\n",
    "\n",
    "        feature_vector.append(np.mean(features.rmse))\n",
    "        feature_vector.append(np.var(features.rmse))\n",
    "\n",
    "        # self.X = np.vstack((self.X,[feature_vector])) \n",
    "        return feature_vector\n",
    "        \n",
    "    def __process_dataset(self):\n",
    "        starttime = time.time()\n",
    "        for i , (dirpath, dirnames, filenames) in enumerate(os.walk(self.DATASET_PATH)):\n",
    "              if dirpath is not self.DATASET_PATH:\n",
    "                label = dirpath.split(\"/\")[-1]\n",
    "                # print(label)\n",
    "                print(\"Processing:\", label)\n",
    "                for file in filenames:\n",
    "                  #load audio\n",
    "                  file_path = os.path.join(dirpath,file)\n",
    "\n",
    "                  # print(file_path)\n",
    "\n",
    "                  #exctract mfcc\n",
    "                try:\n",
    "                    features = FeatureExtraction()\n",
    "                    features.loadFile(file_path)\n",
    "                    features.melspectrogram()\n",
    "                    features.extractmfcc()\n",
    "                    features.extractrmse()\n",
    "                except ValueError:\n",
    "                    self.failed_file.apppend(file_path)\n",
    "\n",
    "                feature_vector = []\n",
    "\n",
    "                for feature in features.mfcc:\n",
    "                    feature_vector.append(np.mean(feature))\n",
    "                    feature_vector.append(np.var(feature))\n",
    "\n",
    "                for feature in features.delta_mfcc:\n",
    "                    feature_vector.append(np.mean(feature))\n",
    "                    feature_vector.append(np.var(feature))\n",
    "\n",
    "                for feature in features.delta2_mfcc:\n",
    "                    feature_vector.append(np.mean(feature))\n",
    "                    feature_vector.append(np.var(feature))\n",
    "\n",
    "                feature_vector.append(np.mean(features.rmse))\n",
    "                feature_vector.append(np.var(features.rmse))\n",
    "\n",
    "                self.X = np.vstack((self.X,[feature_vector]))\n",
    "                if label == 'success':\n",
    "                    self.Y = np.vstack((self.Y,[0,1]))\n",
    "                    self.processed_counter += 1\n",
    "                    print(\"Done \", self.processed_counter, file_path,' label=',label)\n",
    "                elif label == 'stuttered':\n",
    "                    self.Y = np.vstack((self.Y,[1,0]))\n",
    "                    self.processed_counter += 1\n",
    "                    print(\"Done \", self.processed_counter, file_path,' label=',label)\n",
    "                else:\n",
    "                    self.unexpected_label.append(file_path)\n",
    "                    print(\"Fail \", self.processed_counter, file_path,' label=',label)\n",
    "\n",
    "        for fail in self.unexpected_label:\n",
    "            print(\"unexpected_label \", file_path, \" !\")\n",
    "\n",
    "        for fail in self.failed_file:\n",
    "            print(\"fail \", file_path, \" !\")\n",
    "\n",
    "        # print(\"finished all!\")\n",
    "        print('Time taken = {} seconds'.format(time.time() - starttime))    \n",
    "        self.DATASET = np.hstack((self.X,self.Y))\n",
    "\n",
    "    def load_dataset(self,dataset_path):\n",
    "        self.DATASET_PATH = dataset_path\n",
    "\n",
    "        if os.path.exists(self.DATASET_PATH):\n",
    "            print(\"Dataset exist!\")\n",
    "        else:\n",
    "            print('Not found ',self.DATASET_PATH)\n",
    "            return\n",
    "\n",
    "        self.FILE_NAME, self.FILE_TYPE = os.path.splitext(self.DATASET_PATH)\n",
    "\n",
    "        print(\"Loading \", self.DATASET_PATH)\n",
    "        if self.FILE_TYPE == '.csv':\n",
    "            print('Detect as .csv file')\n",
    "            self.DATA = np.genfromtxt(self.DATASET_PATH, delimiter=',')\n",
    "        elif self.FILE_TYPE == '.gz':\n",
    "            print('Detect as .gz file')\n",
    "            self.DATA = np.loadtxt(self.DATASET_PATH)\n",
    "        else:\n",
    "            print(\"Only support .gz and .csv file\")\n",
    "            return False\n",
    "\n",
    "        self.X = self.DATA[:, 0:80]\n",
    "        self.Y = self.DATA[:, 80:]\n",
    "\n",
    "    def convert_to_csv(self,output_file):\n",
    "        if os.path.exists(output_file):\n",
    "            os.remove(output_file)\n",
    "        np.savetxt(output_file,self.DATA, delimiter=',')\n",
    "        print('Converted to',output_file)      \n",
    "\n",
    "    def __write_to_file(self):\n",
    "        if os.path.exists(self.OUTPUT_PATH):\n",
    "            os.remove(self.OUTPUT_PATH)\n",
    "\n",
    "        np.savetxt(self.OUTPUT_PATH, self.DATASET)\n",
    "        print('Saved to',self.OUTPUT_PATH)  \n",
    "\n",
    "    def get_x(self):\n",
    "        return self.X\n",
    "\n",
    "    def get_y(self):\n",
    "        return self.Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timestamp:\n",
    "    def __init__(self,start = 0.0, end = 0.0, word='word', isInclude=False,feature=None, label=None):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.word = word\n",
    "        self.isInclude = isInclude\n",
    "        self.feature = feature\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''auto-editor.py'''\n",
    "#python auto-editor.py lib.mp4 --frame_margin 8 --silent_threshold 0.03\n",
    "# external python libraries\n",
    "from scipy.io import wavfile\n",
    "import soundfile as sf\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# internal python libraries\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import subprocess\n",
    "from shutil import move, rmtree, copyfile\n",
    "\n",
    "import json\n",
    "\n",
    "# tested with VOSK 0.3.15\n",
    "import vosk\n",
    "import librosa\n",
    "import numpy\n",
    "import pandas\n",
    "\n",
    "# developed librLary\n",
    "from Timecode import Timecode\n",
    "\n",
    "class AutoEdit:\n",
    "    def __init__(self, file=None, ba='160000', ac='1', ar='16000',output_format='.wav', fps = 30.0, \n",
    "                 st = 0.04, fm = 4, lt = 2.00, verbose = False,\n",
    "                 log=False, mono = True, \n",
    "                 model='Model/mymodel_78_18.h5'):\n",
    "        #parameter for ffmpeg to convert the file\n",
    "        self.MODEL_PATH = model\n",
    "        self.INPUT_FILE = file\n",
    "        self.FILENAME = file.split('.')[0]\n",
    "        self.AUDIO_OUTPUT_FORMAT = output_format\n",
    "        self.AUDIO_OUTPUT = f'{self.FILENAME}{self.AUDIO_OUTPUT_FORMAT}'\n",
    "        \n",
    "        self.BITRATE_AUDIO = ba\n",
    "        self.AUDIO_CHANEL = ac\n",
    "        self.AUDIO_RATE = ar\n",
    "        self.FRAME_RATE = fps\n",
    "        \n",
    "        self.FRAME_MARGIN = fm\n",
    "        self.SILENT_THRESHOLD = st\n",
    "        self.LOUDNESS_THRESHOLD = lt\n",
    "        \n",
    "        self.VERBOSE = verbose\n",
    "        \n",
    "        self.audioData = None\n",
    "        self.sampleRate = None\n",
    "        \n",
    "        self.audioSampleCount = None\n",
    "        self.maxAudioVolume = None\n",
    "        self.samplesPerFrame = None\n",
    "        self.audioFrameCount = None\n",
    "        self.hasLoudAudio = None\n",
    "        \n",
    "        self.chunks = None\n",
    "        self.shouldIncludeFrame = None\n",
    "        self.timecodeList = None\n",
    "        self.chunks_path = 'chunks.txt'\n",
    "        self.log = log\n",
    "        self.isMono = mono\n",
    "            \n",
    "    def extract_audio(self):\n",
    "        if self.INPUT_FILE == None:\n",
    "            print(\"No input file!\")\n",
    "            \n",
    "        cmd = ['ffmpeg', '-y' ,'-i',self.INPUT_FILE,'-acodec','pcm_s16le' ,'-b:a', self.BITRATE_AUDIO, '-ac', self.AUDIO_CHANEL, \n",
    "               '-ar', self.AUDIO_RATE, '-vn', f'{self.AUDIO_OUTPUT}']\n",
    "        #ffmpeg -i \"%%a\" -acodec pcm_s16le -ac 1 -ar 16000 -af lowpass=3000,highpass=200 \"converted\\%%~na.wav\n",
    "        if(not self.VERBOSE):\n",
    "            cmd.extend(['-nostats', '-loglevel', '0'])\n",
    "        subprocess.call(cmd)\n",
    "        \n",
    "    def get_max_volume(self,s):\n",
    "        maxv = float(np.max(s))\n",
    "        minv = float(np.min(s))\n",
    "        return max(maxv, -minv)\n",
    "\n",
    "    def load_audio(self):\n",
    "        # self.sampleRate,self.audioData = wavfile.read(f'{self.AUDIO_OUTPUT}')\n",
    "        self.audioData,self.sampleRate = librosa.load(f'{self.AUDIO_OUTPUT}',\n",
    "        mono = self.isMono,sr=self.sampleRate)\n",
    "\n",
    "        self.audioSampleCount = self.audioData.shape[0]\n",
    "        self.maxAudioVolume = self.get_max_volume(self.audioData)\n",
    "        self.samplesPerFrame = self.sampleRate / self.FRAME_RATE\n",
    "        self.audioFrameCount = int(math.ceil(self.audioSampleCount / self.samplesPerFrame))\n",
    "    \n",
    "    def get_shape(self):\n",
    "        return self.audioData.shape\n",
    "    \n",
    "    def calc_has_loud_audio(self):\n",
    "        self.hasLoudAudio = np.zeros((self.audioFrameCount))\n",
    "        \n",
    "        for i in range(self.audioFrameCount):\n",
    "            start = int(i * self.samplesPerFrame)\n",
    "            end = min( int( (i+1) * self.samplesPerFrame ), self.audioSampleCount)\n",
    "            audiochunks = self.audioData[start:end]\n",
    "            maxchunksVolume = self.get_max_volume(audiochunks) / self.maxAudioVolume\n",
    "            \n",
    "            if(maxchunksVolume >= self.LOUDNESS_THRESHOLD):\n",
    "                self.hasLoudAudio[i] = 2\n",
    "            elif(maxchunksVolume >= self.SILENT_THRESHOLD):\n",
    "                self.hasLoudAudio[i] = 1\n",
    "    \n",
    "    def calc_should_include_frame(self):\n",
    "        self.shouldIncludeFrame = np.zeros((self.audioFrameCount))\n",
    "        self.chunks = [[0,0,0]]\n",
    "        \n",
    "        for i in range(self.audioFrameCount):\n",
    "            start = int(max(0, i-self.FRAME_MARGIN))\n",
    "            end = int(min(self.audioFrameCount, i+1+self.FRAME_MARGIN))\n",
    "            self.shouldIncludeFrame[i] = min(1,np.max(self.hasLoudAudio[start:end]))\n",
    "\n",
    "            if(i >= 1 and self.shouldIncludeFrame[i] != self.shouldIncludeFrame[i-1]):\n",
    "                self.chunks.append([self.chunks[-1][1], i, self.shouldIncludeFrame[i-1]])\n",
    "        self.chunks.append([self.chunks[-1][1], self.audioFrameCount, self.shouldIncludeFrame[i-1]])\n",
    "        self.chunks = self.chunks[1:]\n",
    "        \n",
    "    def calc_timecode(self):\n",
    "        self.timecodeList = []\n",
    "        \n",
    "        for chunk in self.chunks:\n",
    "            startTime = Timecode(fps=self.FRAME_RATE)\n",
    "            endTime = Timecode(fps=self.FRAME_RATE)\n",
    "            \n",
    "            startTime.set_by_frames(chunk[0])\n",
    "            endTime.set_by_frames(chunk[1])\n",
    "            isInclude = chunk[2]\n",
    "            self.timecodeList.append([startTime,endTime,isInclude])\n",
    "            \n",
    "    def execute(self):\n",
    "        command = 'run.bat'\n",
    "        if os.path.exists('run.bat'):\n",
    "            if self.log:\n",
    "                 command += ' > log.txt'    \n",
    "            output = subprocess.call(command,shell=True)\n",
    "        if self.VERBOSE:\n",
    "            print(\"Complex frilter command success\") if output == 0 else print(\"Complex filter command failed!\")\n",
    "      \n",
    "            \n",
    "            \n",
    "    def write_to_bat(self,command):\n",
    "        if os.path.exists('run.bat'):\n",
    "            os.remove(f'run.bat')\n",
    "        file1 = open(\"run.bat\",\"w\")\n",
    "        file1.write(command)\n",
    "        file1.close()\n",
    "        filename = 'run.bat'\n",
    "        if self.log:\n",
    "            filename += ' > log.txt'\n",
    "        return filename\n",
    "    \n",
    "    def produce_concat_file(self):\n",
    "        if os.path.exists(self.chunks_path):\n",
    "            os.remove(self.chunks_path)\n",
    "            \n",
    "        with open(self.chunks_path, 'w') as f:\n",
    "            for index in range(len(self.timecodeList)):\n",
    "                isInclude = float(self.timecodeList[index][2])\n",
    "                if isInclude < 1:\n",
    "                    continue;\n",
    "                # startTime = self.timecodeList[index][0].get_timecode_ffmpeg()\n",
    "                # endTime = self.timecodeList[index][1].get_timecode_ffmpeg()\n",
    "                startTime = self.timecodeList[index][0].get_seconds()\n",
    "                endTime = self.timecodeList[index][1].get_seconds()\n",
    "                f.write(f'file {self.INPUT_FILE}\\ninpoint {startTime}\\noutpoint {endTime}\\n')\n",
    "    \n",
    "    def concat_way(self):\n",
    "        concat = ['ffmpeg','-y','-f','concat','-safe','0','-i', f'{self.chunks_path}',\n",
    "                 '-async','1','-framerate', f'{self.FRAME_RATE}','-b:a', f'{self.BITRATE_AUDIO}',\n",
    "                 '-c:v', 'copy', '-ar', f'{self.AUDIO_RATE}', '-ac', f'{self.AUDIO_CHANEL}',\n",
    "                 '-c:a','aac','-movflags','+faststart',f'{self.FILENAME}_CONCATED.mp4']\n",
    "        subprocess.call(concat)\n",
    "        \n",
    "    def select_filter(self):\n",
    "        \n",
    "        between = []\n",
    "        counter = 0\n",
    "        for i in self.timecodeList:\n",
    "            if i[2] > 0:\n",
    "#                 print(f'{self.INPUT_FILE},{i[0].get_seconds()},{i[1].get_seconds()}')\n",
    "                between.append(f'between(t,{i[0].get_seconds()},{i[1].get_seconds()})') \n",
    "        \n",
    "        betweens = '+'.join(between)\n",
    "        slt = '\\\"select=\\'' + betweens + '\\'' + ',setpts=N/FRAME_RATE/TB\\\"'\n",
    "        aslt = '\\\"aselect=\\'' + betweens + '\\'' + ',asetpts=N/SR/TB\\\"'\n",
    "        \n",
    "        sltFilter = ['ffmpeg','-y','-i',f'{self.INPUT_FILE}', '-vf', \n",
    "                     f'{slt}','-af', f'{aslt}',\n",
    "                     f'{self.FILENAME}_FILTERED.mp4']\n",
    "        \n",
    "        total_string = ' '.join(sltFilter)\n",
    "#         if self.log:\n",
    "#             total_string += \" > log.txt 2>&1\";\n",
    "        bat_path = self.write_to_bat(total_string)\n",
    "        output = subprocess.call(bat_path,shell=True)\n",
    "        if self.VERBOSE:\n",
    "            print(\"Select filter command success\") if output == 0 else print(\"Select filter command failed!\")\n",
    "            \n",
    "    def remove_silence(self):\n",
    "        trim = []\n",
    "        duration_list = []\n",
    "        number_of_segment = 0\n",
    "        prev = 0\n",
    "        current = 0\n",
    "\n",
    "        # with out xfade\n",
    "        for i in self.timecodeList:\n",
    "            if i[2] > 0:\n",
    "                duration_list.append(i[0].get_seconds()-i[1].get_seconds())\n",
    "                trim.append(\n",
    "                    f'[0:v]trim=start={i[0].get_seconds()}:end={i[1].get_seconds()},setpts=PTS-STARTPTS[v{number_of_segment}]')\n",
    "                trim.append(\n",
    "                    f'[0:a]atrim=start={i[0].get_seconds()}:end={i[1].get_seconds()},asetpts=PTS-STARTPTS[a{number_of_segment}]')\n",
    "                number_of_segment += 1\n",
    "\n",
    "                \n",
    "        filter = ';'.join(trim)\n",
    "        filter = filter + \";\"\n",
    "\n",
    "        # Normal cut feature\n",
    "        for i in range(number_of_segment):\n",
    "            filter += f' [v{i}] [a{i}]'\n",
    "\n",
    "        # Start to generate ending of command\n",
    "        filter += f'concat=n={number_of_segment}:v=1:a=1 [out]'\n",
    "        filter = '\"' + filter + '\"'\n",
    "        filter = f'ffmpeg -y -i {self.INPUT_FILE} -filter_complex ' + filter\n",
    "        filter = filter + f' -map \"[out]\" {self.FILENAME}_SILENCE.mp4'\n",
    "            \n",
    "        bat_path = self.write_to_bat(filter)     \n",
    "    \n",
    "\n",
    "    def fliter_complex(self):\n",
    "        trim = []\n",
    "        duration_list = []\n",
    "        number_of_segment = 0\n",
    "        prev = 0\n",
    "        current = 0\n",
    "\n",
    "        # with out xfade\n",
    "        for i in self.timecodeList:\n",
    "            if i[2] > 0:\n",
    "                duration_list.append(i[0].get_seconds()-i[1].get_seconds())\n",
    "                trim.append(\n",
    "                    f'[0:v]trim=start={i[0].get_seconds()}:end={i[1].get_seconds()},setpts=PTS-STARTPTS[v{number_of_segment}]')\n",
    "                trim.append(\n",
    "                    f'[0:a]atrim=start={i[0].get_seconds()}:end={i[1].get_seconds()},asetpts=PTS-STARTPTS[a{number_of_segment}]')\n",
    "                number_of_segment += 1\n",
    "\n",
    "        # # with xfade\n",
    "        # for i in self.timecodeList:\n",
    "        #     if i[2] > 0:\n",
    "        #         duration_list.append(i[1].get_seconds()-i[0].get_seconds())\n",
    "        #         trim.append(\n",
    "        #             f'[0:v]trim=start={i[0].get_seconds()}:end={i[1].get_seconds()},setpts=PTS-STARTPTS[v{number_of_segment}]')\n",
    "        #         number_of_segment += 1\n",
    "        # number_of_segment = 0\n",
    "        # for i in self.timecodeList:\n",
    "        #     if i[2] > 0:\n",
    "        #         trim.append(\n",
    "        #             f'[0:a]atrim=start={i[0].get_seconds()}:end={i[1].get_seconds()},asetpts=PTS-STARTPTS[a{number_of_segment}]')\n",
    "        #         number_of_segment += 1\n",
    "                \n",
    "        filter = ';'.join(trim)\n",
    "        filter = filter + \";\"\n",
    "\n",
    "        # Normal cut feature\n",
    "        for i in range(number_of_segment):\n",
    "            filter += f' [v{i}] [a{i}]'\n",
    "\n",
    "        # # Generate for xfade effect\n",
    "        # prevOffset = 0\n",
    "        # count = 1\n",
    "        # for i in range(number_of_segment):\n",
    "        #     offset = duration_list[i] + prevOffset - 0.5\n",
    "        #     if(i < 2):\n",
    "        #         filter += f'[v{i}]'\n",
    "        #     if(i == 2):\n",
    "        #         filter += f'xfade=transition=fade:duration=0.5:offset={offset}'\n",
    "        #         filter += f'[x{count}];'\n",
    "        #         filter += f'[x{count}]'\n",
    "        #         filter += f'[v{i}]'\n",
    "        #         filter += f'xfade=transition=fade:duration=0.5:offset={offset}'\n",
    "        #         count += 1\n",
    "        #         filter += f'[x{count}];'\n",
    "        #     if(i > 2):\n",
    "        #         filter += f'[x{count}]'\n",
    "        #         filter += f'[v{i}]'\n",
    "        #         filter += f'xfade=transition=fade:duration=0.5:offset={offset}'\n",
    "        #         count += 1\n",
    "        #         if(i == number_of_segment - 1):\n",
    "        #             filter += f',format=yuv420p'\n",
    "        #         filter += f'[x{count}];'\n",
    "        #     prevOffset = offset\n",
    "\n",
    "        # for i in range(number_of_segment):\n",
    "        #     filter += f' [a{i}]'\n",
    "\n",
    "        # Start to generate ending of command\n",
    "        filter += f'concat=n={number_of_segment}:v=1:a=1 [out]'\n",
    "        filter = '\"' + filter + '\"'\n",
    "        filter = f'ffmpeg -y -i {self.INPUT_FILE} -filter_complex ' + filter\n",
    "        filter = filter + f' -map \"[out]\" {self.FILENAME}_COMPLEX.mp4'\n",
    "\n",
    "\n",
    "#         if self.log:\n",
    "#             filter += ' > \"log.txt\" 2>&1'\n",
    "            \n",
    "        bat_path = self.write_to_bat(filter)\n",
    "#         output = subprocess.call(bat_path,shell=True)\n",
    "        output = 1\n",
    "        if self.VERBOSE:\n",
    "            print(\"Complex frilter command success\") if output == 0 else print(\"Complex filter command failed!\")\n",
    "    \n",
    "    \n",
    "    def post_process(self):\n",
    "        if os.path.exists(f'{self.chunks_path}'):\n",
    "            os.remove(f'{self.chunks_path}')\n",
    "            if self.VERBOSE:\n",
    "                print(f\"Removed {self.chunks_path}\")\n",
    "                \n",
    "        if os.path.exists(f'{self.AUDIO_OUTPUT}'):\n",
    "            os.remove(f'{self.AUDIO_OUTPUT}')\n",
    "            if self.VERBOSE:\n",
    "                print(f\"Removed {self.AUDIO_OUTPUT}\")\n",
    "       \n",
    "        \n",
    "    def export_complex(self):\n",
    "        self.pbar = tqdm(total=7)\n",
    "        print(\"Start processing...\")\n",
    "        self.extract_audio()\n",
    "        self.update_mypbar()\n",
    "        self.load_audio()\n",
    "        self.update_mypbar()\n",
    "        self.calc_has_loud_audio()\n",
    "        self.update_mypbar()\n",
    "        self.calc_should_include_frame()\n",
    "        self.update_mypbar()\n",
    "        self.calc_timecode()\n",
    "        self.update_mypbar()\n",
    "        \n",
    "        print(f'Exporting {self.FILENAME}_COMPLEX.mp4 ...')\n",
    "        self.fliter_complex()\n",
    "        self.update_mypbar()\n",
    "        print(f'Exported {self.FILENAME}_COMPLEX.mp4 successfully!')\n",
    "        \n",
    "        self.post_process()\n",
    "        self.update_mypbar()\n",
    "        self.pbar.close()\n",
    "        \n",
    "    def export_fast(self):\n",
    "        try:\n",
    "            self.extract_audio()\n",
    "            self.load_audio()\n",
    "            self.calc_has_loud_audio()\n",
    "            self.calc_should_include_frame()\n",
    "            self.calc_timecode()\n",
    "            self.produce_concat_file()\n",
    "            self.concat_way()\n",
    "            self.post_process()\n",
    "            if(self.VERBOSE):\n",
    "                print(f'Exported {self.FILENAME}_CONCATED.mp4 successfully!')\n",
    "        except:\n",
    "            print('Failed to export fast!')\n",
    "            \n",
    "    def update_mypbar(self):\n",
    "        self.pbar.update(1)\n",
    "        time.sleep(0.01)\n",
    "        self.pbar.refresh()\n",
    "            \n",
    "    def export_good(self):\n",
    "        self.pbar = tqdm(total=7)\n",
    "        try:\n",
    "            print(\"Start processing...\")\n",
    "            self.extract_audio()\n",
    "            self.update_mypbar()\n",
    "\n",
    "            self.load_audio()\n",
    "            self.update_mypbar()\n",
    "\n",
    "            self.calc_has_loud_audio()\n",
    "            self.update_mypbar()\n",
    "            self.calc_should_include_frame()\n",
    "            self.update_mypbar()\n",
    "            self.calc_timecode()\n",
    "            self.update_mypbar()\n",
    "            \n",
    "            print(f'Exporting {self.FILENAME}_FILTERED.mp4 ...')\n",
    "            self.select_filter()\n",
    "            self.update_mypbar()\n",
    "            print(f'Exported {self.FILENAME}_FILTERED.mp4 successfully!')\n",
    "  \n",
    "            self.post_process()\n",
    "            self.update_mypbar()\n",
    "            self.pbar.close()\n",
    "        except:\n",
    "            print(f'Failed to export {self.FILENAME}_FILTERED.mp4 !')\n",
    "            \n",
    "    def extract_words(self,res):\n",
    "        jres = json.loads(res)\n",
    "        if not 'result' in jres:\n",
    "            return []\n",
    "        words = jres['result']\n",
    "        return words\n",
    "\n",
    "    def transcribe_words(self,recognizer, bytes):\n",
    "        results = []\n",
    "\n",
    "        chunk_size = 4000\n",
    "        for chunk_no in range(math.ceil(len(bytes)/chunk_size)):\n",
    "            start = chunk_no*chunk_size\n",
    "            end = min(len(bytes), (chunk_no+1)*chunk_size)\n",
    "            data = bytes[start:end]\n",
    "\n",
    "            if recognizer.AcceptWaveform(data):\n",
    "                words = self.extract_words(recognizer.Result())\n",
    "                results += words\n",
    "        results += self.extract_words(recognizer.FinalResult())\n",
    "\n",
    "        return results                \n",
    "\n",
    "    def vosk_process(self):\n",
    "        print('Loading vosk...')\n",
    "        vosk.SetLogLevel(-1)\n",
    "        int16 = np.int16(self.audioData * 32768).tobytes()\n",
    "        model_path='vosk-model-en-us-aspire-0.2'\n",
    "        vosk_model = vosk.Model(model_path)\n",
    "        recognizer = vosk.KaldiRecognizer(vosk_model, 16000)\n",
    "        print('Transcribing...')\n",
    "        res = self.transcribe_words(recognizer, int16)\n",
    "        df = pandas.DataFrame.from_records(res)\n",
    "        df = df.sort_values('start')\n",
    "        print('Completed transcribe')\n",
    "        self.df = df\n",
    "        \n",
    "        \n",
    "    def feature_process(self):\n",
    "        # Process by using vosk\n",
    "        self.audioData\n",
    "        df = self.df\n",
    "        model = tf.keras.models.load_model(self.MODEL_PATH)\n",
    "        feature_file = f'{self.FILENAME}_feature.csv'\n",
    "        \n",
    "        sampleRate = cut.sampleRate\n",
    "        fail_list = []\n",
    "        time_margin = int( (  (1/self.FRAME_RATE) *self.FRAME_MARGIN ) )\n",
    "        index_margin = int( (  (1/self.FRAME_RATE) *self.FRAME_MARGIN ) *self.sampleRate )\n",
    "\n",
    "        if(os.path.exists(feature_file)):\n",
    "            os.remove(feature_file)\n",
    "\n",
    "        if(not os.path.exists(feature_file)):\n",
    "            print(\"Extracting feature...\")\n",
    "            features = np.empty(shape=(0,80))\n",
    "            ds = Dataset()\n",
    "            for i in tqdm(df.index[:]): \n",
    "        #         start_index = int(df['start'][i] * sampleRate)\n",
    "        #         end_index = int(df['end'][i] * sampleRate)\n",
    "                start_index = max(0, int(  df['start'][i] * self.sampleRate))\n",
    "                end_index = min( int( (df['end'][i]) * self.sampleRate), self.audioSampleCount)\n",
    "        #         try:\n",
    "                fea = ds.get_feature_by_audio(self.audioData[start_index:end_index],11025)\n",
    "                features = np.vstack((features,[fea]))\n",
    "        #         except:\n",
    "        #             ts = Timestamp(df['start'][i],df['end'][i],word=df['word'][i])\n",
    "        #             fail_list.append(ts)\n",
    "        #             print('Failed index:',i)\n",
    "            print(f'Saved features to {feature_file}')\n",
    "            np.savetxt(feature_file, features, delimiter=',')\n",
    "\n",
    "\n",
    "        print(f'Load feature from {feature_file}')\n",
    "        features = np.loadtxt(feature_file,delimiter=',')\n",
    "\n",
    "        print('Predicting...')\n",
    "        predictions = model.predict(x=features, batch_size=84,verbose=0)\n",
    "        print(\"Finish predict!\")\n",
    "\n",
    "        self.predictions = predictions\n",
    "        include_list = []\n",
    "        for i in tqdm(df.index[:]):\n",
    "            isInclude = True\n",
    "            predict = np.round(predictions[i])\n",
    "            word = df['word'][i]\n",
    "            if(word == \"i'm\" or word == 'um' or word =='m' or word=='ah'or word=='huh'or word=='hm'):\n",
    "                if(predict == 1):\n",
    "                    isInclude = False\n",
    "            if(isInclude):\n",
    "                start = df['start'][i]\n",
    "                end = df['end'][i]\n",
    "                ts = Timestamp(start,end,word=word,label=predict)\n",
    "                include_list.append(ts)\n",
    "                \n",
    "        self.include_list = include_list        \n",
    "        render_list = []\n",
    "        counter = 0\n",
    "        start = include_list[0].start\n",
    "        end = include_list[0].end\n",
    "        word = \"\"\n",
    "        for i,ts in tqdm(enumerate(include_list)):\n",
    "            current_start = ts.start\n",
    "            current_end = ts.end\n",
    "            prev_start = include_list[i-1].start\n",
    "            prev_end = include_list[i-1].end\n",
    "            if(i >= 1 and current_start != prev_end):\n",
    "                segment = Timestamp(start,prev_end, word=word)\n",
    "                word = ''\n",
    "                start = current_start\n",
    "                render_list.append(segment)\n",
    "                counter = counter + 1\n",
    "            word = word + ts.word + \" \"\n",
    "#             print(segment.start, \" \", segment.end,\" \", segment.word)        \n",
    "\n",
    "        self.render_list = render_list\n",
    "        \n",
    "#         df = self.df\n",
    "#         model = tf.keras.models.load_model(f'{self.MODEL_PATH}')\n",
    "#         feature_file = f'{self.FILENAME}_feature.csv'\n",
    "# #         df = self.df\n",
    "# #         sampleRate = self.sampleRate\n",
    "#         fail_list = []\n",
    "#         time_margin = int( (  (1/self.FRAME_RATE) *self.FRAME_MARGIN ) )\n",
    "#         index_margin = int( (  (1/self.FRAME_RATE) *self.FRAME_MARGIN ) *self.sampleRate )\n",
    "        \n",
    "#         if(os.path.exists(feature_file)):\n",
    "#             os.remove(feature_file)\n",
    "\n",
    "#         if(not os.path.exists(feature_file)):\n",
    "# #             print('No feature cache')\n",
    "#             print(\"Extracting feature...\")\n",
    "#             features = np.empty(shape=(0,80))\n",
    "#             ds = Dataset()\n",
    "#             for i in tqdm(df.index[:]): \n",
    "#                 start_index = max(0, int(  df['start'][i] * self.sampleRate))\n",
    "#                 end_index = min( int( (df['end'][0]) * self.sampleRate), self.audioSampleCount)\n",
    "#                 fea = ds.get_feature_by_audio(self.audioData[start_index:end_index],11025)\n",
    "#                 features = np.vstack((features,[fea]))\n",
    "#             print(f'Saved features to {feature_file}')\n",
    "#             np.savetxt(feature_file, features, delimiter=',')\n",
    "\n",
    "\n",
    "#         print(f'Load feature from {feature_file}')\n",
    "#         features = np.loadtxt(feature_file,delimiter=',')\n",
    "\n",
    "#         print('Predicting...')\n",
    "#         predictions = model.predict(x=features, batch_size=84,verbose=0)\n",
    "#         print(\"Finish predict!\")\n",
    "#         self.predictions = predictions\n",
    "\n",
    "#         include_list = []\n",
    "#         for i in tqdm(df.index[:]):\n",
    "#             isInclude = True\n",
    "#             predict = np.round(predictions[i])\n",
    "#             word = df['word'][i]\n",
    "#             if(word == \"i'm\" or word == 'um' or word =='m'):\n",
    "#                 if(predict == 1):\n",
    "#                     isInclude = False\n",
    "#             if(isInclude):\n",
    "#                 start = df['start'][i]\n",
    "#                 end = df['end'][i]\n",
    "#                 ts = Timestamp(start,end,word=word,label=predict)\n",
    "#                 include_list.append(ts)\n",
    "                \n",
    "#         self.include_list = include_list\n",
    "#         render_list = []\n",
    "#         counter = 0\n",
    "#         start = include_list[0].start\n",
    "#         end = include_list[0].end\n",
    "#         word = \"\"\n",
    "#         for i,ts in tqdm(enumerate(include_list)):\n",
    "#             current_start = ts.start\n",
    "#             current_end = ts.end\n",
    "#             prev_start = include_list[i-1].start\n",
    "#             prev_end = include_list[i-1].end\n",
    "#             if(i >= 1 and current_start != prev_end):\n",
    "#                 segment = Timestamp(start,prev_end, word=word)\n",
    "#                 word = ''\n",
    "#                 start = current_start\n",
    "#                 render_list.append(segment)\n",
    "#                 counter = counter + 1\n",
    "#             word = word + ts.word + \" \"\n",
    "#         self.predictions = predictions\n",
    "#         self.include_list = include_list\n",
    "#         self.render_list = render_list\n",
    "            \n",
    "\n",
    "\n",
    "    def generate_complex_filter(self,render_list):\n",
    "        trim = []\n",
    "        duration_list = []\n",
    "        number_of_segment = 0\n",
    "        prev = 0\n",
    "        current = 0\n",
    "        # with out xfade\n",
    "        for ts in render_list:\n",
    "            duration_list.append(ts.end-ts.start)\n",
    "            trim.append(\n",
    "                f'[0:v]trim=start={ts.start}:end={ts.end},setpts=PTS-STARTPTS[v{number_of_segment}]')\n",
    "            trim.append(\n",
    "                f'[0:a]atrim=start={ts.start}:end={ts.end},asetpts=PTS-STARTPTS[a{number_of_segment}]')\n",
    "            number_of_segment += 1\n",
    "\n",
    "        filter = ';'.join(trim)\n",
    "        filter = filter + \";\"\n",
    "\n",
    "        # Normal cut feature\n",
    "        for i in range(number_of_segment):\n",
    "            filter += f' [v{i}] [a{i}]'\n",
    "\n",
    "\n",
    "        # Start to generate ending of command\n",
    "        filter += f'concat=n={number_of_segment}:v=1:a=1 [out]'\n",
    "        filter = '\"' + filter + '\"'\n",
    "        filter = f'ffmpeg -y -i {cut.INPUT_FILE} -filter_complex ' + filter\n",
    "        filter = filter + f' -map \"[out]\" {cut.FILENAME}_COMPLEX.mp4'\n",
    "        bat_path = self.write_to_bat(filter)\n",
    "        \n",
    "        \n",
    "#     print(segment.start, \" \", segment.end,\" \", segment.word)\n",
    "        \n",
    "        \n",
    "# All below is overlap technique\n",
    "        \n",
    "        \n",
    "#         segment_length = 300\n",
    "#         segment_hop = 100\n",
    "#         samples_per_segment = int(segment_length * self.sampleRate / 1000)\n",
    "#         samples_to_skip_per_hop = int(segment_hop * self.sampleRate / 1000)\n",
    "#         print('samples_per_segment:',samples_per_segment,' samples_to_skip_per_hop',samples_to_skip_per_hop)\n",
    "#         ts_list_index = []\n",
    "        \n",
    "#         ts_list = []\n",
    "#         for ts in self.timecodeList:\n",
    "#             if ts[2] > 0:\n",
    "#                 ts_list.append(ts)\n",
    "#         self.ts_list = ts_list\n",
    "\n",
    "\n",
    "# \"\"\" remove this first to use the first overlap technique   \n",
    "# #         Implementing overlap technique\n",
    "\n",
    "# #         convert the time in seconds to index (sample rate) for audio data\n",
    "#         counter = 0\n",
    "#         for timecode in ts_list:\n",
    "#             if timecode[2] > 0:\n",
    "#                 start_time = float(timecode[0].get_seconds())\n",
    "#                 end_time = float(timecode[1].get_seconds())\n",
    "#                 start_index = int(start_time * self.sampleRate)\n",
    "#                 end_index = int(end_time * self.sampleRate)\n",
    "#                 # start_index = librosa.time_to_samples(start_time)\n",
    "#                 # end_index = librosa.time_to_samples(end_time)\n",
    "#                 ts = Timestamp(start_index,end_index,timecode[2])\n",
    "# #                 sf.write(f'temp/{counter}.wav',self.audioData[start_index:end_index],self.sampleRate)\n",
    "#                 counter = counter + 1\n",
    "#                 ts_list_index.append(ts)\n",
    "#         # for tx in ts_list_index:\n",
    "#         #     print('start:',tx.start,'end:',tx.end)\n",
    "#         # print(\"====\")\n",
    "        \n",
    "#         self.ts_list_index = ts_list_index\n",
    "        \n",
    "# #         generate overlapping file\n",
    "#         hop_list = []\n",
    "#         for ts in ts_list_index:\n",
    "#             for start_index in range(ts.start,ts.end,samples_to_skip_per_hop):\n",
    "#                 end = start_index+samples_per_segment\n",
    "# #                 print('start:',start_index,'end:',end)\n",
    "#                 hop = Timestamp(start_index,end,ts.label)\n",
    "#                 hop_list.append(hop)\n",
    "\n",
    "#         # for hop in hop_list:\n",
    "#         #     print('start:',hop.start,'end:',hop.end,'isInclude',hop.isInclude)\n",
    "\n",
    "# #         Detect cached feature file if not generate the feature and store it as csv\n",
    "#         feature_file = f'{self.FILENAME}_feature.csv'\n",
    "#         if(not os.path.exists(feature_file)):            \n",
    "#             ds = Dataset()\n",
    "#             print(\"Extracting feature...\")\n",
    "#             features = np.empty(shape=(0,80))\n",
    "#             for hop in hop_list:\n",
    "# #                 audioData = librosa.core.resample(self.audioData[hop.start:hop.end],\n",
    "# #                                                   self.sampleRate,target_sr=11025)\n",
    "#                 fea = ds.get_feature_by_audio(self.audioData[hop.start:hop.end],11025)\n",
    "#                 hop.feature = np.array(([fea]))\n",
    "#                 features = np.vstack((features,[fea]))\n",
    "#             print(f'Saved features to {feature_file}')\n",
    "#             np.savetxt(feature_file, features, delimiter=',')   \n",
    "# #             else load the features from the cached csv file\n",
    "#         else:\n",
    "#             print(f'Load feature from {feature_file}')\n",
    "#             features = np.loadtxt(feature_file,delimiter=',')\n",
    "# #         promote hop_list for testing purpose\n",
    "#         self.hop_list = hop_list\n",
    "#         print(\"Finish extract feature!\")\n",
    "# #         load the model\n",
    "#         model = tf.keras.models.load_model(self.MODEL_PATH)\n",
    "#         print('Predicting...')\n",
    "#         self.predictions = model.predict(x=features, batch_size=20,verbose=0)\n",
    "#         print(\"Finish predict!\")\n",
    "#         for i,hop in enumerate(self.hop_list):\n",
    "#             hop.label = np.round(self.predictions[i])\n",
    "\n",
    "\n",
    "# #             if previous and current label is stuttered so eliminate the current hop\n",
    "\n",
    "# #         prevLabel = 0\n",
    "# #         self.isInclude = []\n",
    "# #         for hop in self.hop_list:\n",
    "# #             if(hop.label == 0):\n",
    "# #                 self.isInclude.append(hop)\n",
    "# #             elif(hop.label == 1 and prevLabel == 0):\n",
    "# #                 self.isInclude.append(hop)\n",
    "# #             prevLabel = hop.label\n",
    "            \n",
    "# #         self.isSegment = []\n",
    "# #         index = 0\n",
    "# #         end = 0\n",
    "# #         start = 0\n",
    "                \n",
    "                \n",
    "            \n",
    "# # implement own technique                \n",
    "            \n",
    "# #    Assign label for the hop in hop list\n",
    "# # This part improve by the batch preductions at above\n",
    "# # Significantly increase the performance\n",
    "\n",
    "# #         for hop in hop_list:\n",
    "# #             lbl = model.predict(hop.feature)\n",
    "# #             hop.label = np.round(lbl[0][0])\n",
    "# #         labels = []\n",
    "# #         print('Finish predict!')\n",
    "\n",
    "\n",
    "# # assign the predicted label to labels list\n",
    "# # extract label from the hop list to generate another list called labels for\n",
    "# # below process\n",
    "\n",
    "# #         for i,hop in enumerate(hop_list):\n",
    "# #             print(hop.label)\n",
    "# #             labels.append(hop.label)\n",
    "\n",
    "# # Divide all segment by 3 to calculate the should include frame\n",
    "\n",
    "# #         number_of_segment = int(len(hop_list)/3)\n",
    "# #         rest_number_of_segment = int(len(hop_list)%3)\n",
    "# #         print(\"Hop-len:\",number_of_segment)\n",
    "# #         print(\"Rest-len:\",rest_number_of_segment)\n",
    "# #         segment = []\n",
    "# #         segment_count = 0\n",
    "# #         for i in range(number_of_segment):\n",
    "# #             hop = hop_list[i]\n",
    "# #             ts = Timestamp()\n",
    "# #             print(hop.start,\" \",hop.end)\n",
    "\n",
    "            \n",
    "# #          print all needed segment start time and endime\n",
    "\n",
    "#         # print(f\"start_time: {start_time} end_time: {end_time} duration:{end_time - start_time} start_index: {start_index} end_index: {end_index}\")\n",
    "\n",
    "#         # for i,timecode in enumerate(ts_list_index):\n",
    "#         #     start_index = timecode.start\n",
    "#         #     end_index = timecode.end\n",
    "#         #     for j in range(start_index,end_index,150):\n",
    "#         #         print(j)\n",
    "#         #     if i > 1:\n",
    "#         #         break\n",
    "\n",
    "\n",
    "# #         export each segment to individual wav file\n",
    "\n",
    "#         # # Work successful to export each segment\n",
    "#         # if os.path.exists('temp/segment'):\n",
    "#         #     shutil.rmtree('temp/segment')\n",
    "#         # if not os.path.exists('temp'):\n",
    "#         #     os.mkdir('temp')\n",
    "#         # if not os.path.exists('temp/segment'):\n",
    "#         #     os.mkdir('temp/segment')\n",
    "#         # for i, timecode in enumerate(ts_list_index):\n",
    "#         #     librosa.output.write_wav(f'temp/segment/{i}.wav',\n",
    "#                     y=self.audioData[timecode.start:timecode.end],sr=self.sampleRate)\n",
    "    \n",
    "# \"\"\" remove this first to use the first overlap technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vosk...\n",
      "Transcribing...\n",
      "Completed transcribe\n"
     ]
    }
   ],
   "source": [
    "cut = AutoEdit(file='SBHD.mp4',ac='1',\n",
    "               verbose=True,fm=4,st=0.2,fps=24.00,\n",
    "               log=True,mono=True,\n",
    "               model='Model/mymodel/mymodel_78_18.h5' #159\n",
    "#                model='Model/newmodel/20201227-1123-MLP-RMSprop-Default-80-123.h5' #100\n",
    "#                model='test1/model-ep202-loss0.145-acc0.889-val_loss0.176-val_acc0.877.h5' #135\n",
    "#                model='test2/model-ep007-loss21.212-acc0.550-val_loss0.443-val_acc0.912.h5' #153\n",
    "#                model='test2/20201228-0913-MLP1.2k-ADAM-BC-relu-sigmoid-75-96.h5' #120\n",
    "#                model = '20201228-0824-MLP1.2k-ADAM-MSE-relu-sigmoid-73-32.h5' #117\n",
    "#                model = '20201228-0152-MLP-ADAM-MS-tanh-sigmoid-75-17.h5'#120\n",
    "#                model ='20201228-0152-MLP-ADAM-MSE-77-16.h5' #96      \n",
    "#                model = 'test1/20201228-0824-MLP-ADAM-MSE-relu-sigmoid-77-23.h5' #120\n",
    "              )\n",
    "cut.extract_audio()\n",
    "cut.load_audio()\n",
    "# cut.calc_has_loud_audio()\n",
    "# cut.calc_should_include_frame()\n",
    "# cut.calc_timecode()\n",
    "cut.vosk_process()\n",
    "# cut.process_feature_vosk()\n",
    "# cut.export_good()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut.MODEL_PATH = 'Model/newmodel/20201227-1123-MLP-RMSprop-Default-80-123.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|                                                                                | 8/542 [00:00<00:07, 74.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting feature...\n",
      "Object created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|                                                                            | 30/542 [00:00<00:05, 87.16it/s]C:\\Users\\mingb\\anaconda3\\envs\\pythonGPU\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1445\n",
      "  warnings.warn(\n",
      "C:\\Users\\mingb\\anaconda3\\envs\\pythonGPU\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=955\n",
      "  warnings.warn(\n",
      " 33%|                                                    | 180/542 [00:01<00:03, 107.59it/s]C:\\Users\\mingb\\anaconda3\\envs\\pythonGPU\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1921\n",
      "  warnings.warn(\n",
      " 62%|                             | 338/542 [00:03<00:01, 109.17it/s]C:\\Users\\mingb\\anaconda3\\envs\\pythonGPU\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=2012\n",
      "  warnings.warn(\n",
      " 81%|              | 440/542 [00:04<00:00, 110.76it/s]C:\\Users\\mingb\\anaconda3\\envs\\pythonGPU\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1438\n",
      "  warnings.warn(\n",
      "100%|| 542/542 [00:05<00:00, 103.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved features to SBHD_feature.csv\n",
      "Load feature from SBHD_feature.csv\n",
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 542/542 [00:00<00:00, 18115.49it/s]\n",
      "515it [00:00, 172089.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish predict!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cut.feature_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex frilter command success\n"
     ]
    }
   ],
   "source": [
    "cut.generate_complex_filter(cut.render_list)\n",
    "cut.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.47   1.86   oh   [0.]\n",
      "3.06   3.42   oh   [0.]\n",
      "3.48   3.75   shit   [0.]\n",
      "7.8   8.07   ah   [1.]\n",
      "8.1   9.06   hua   [0.]\n",
      "9.06   9.27   lots   [0.]\n",
      "9.27   9.42   of   [1.]\n",
      "9.42   9.9   guys   [1.]\n",
      "12.48   12.66   i'm   [0.]\n",
      "12.66   13.17   judy   [0.]\n",
      "13.41   13.889988   and   [0.]\n",
      "14.28   14.43   i   [0.]\n",
      "14.43   14.76   was   [1.]\n",
      "14.94   15.27   wanting   [0.]\n",
      "15.27   15.39   to   [0.]\n",
      "15.39   15.57   make   [0.]\n",
      "15.57   15.780038   this   [0.]\n",
      "15.780038   16.83   shoe   [0.]\n",
      "16.83   17.009954   our   [0.]\n",
      "17.009954   17.19   little   [0.]\n",
      "17.19   17.61   real   [0.]\n",
      "21.0   21.81   about   [0.]\n",
      "21.87   23.37   whites   [0.]\n",
      "23.49   24.48   us   [0.]\n",
      "25.23   25.56   a   [1.]\n",
      "25.59   26.55   sapphire   [0.]\n",
      "26.55   26.88   ring   [0.]\n",
      "26.91   27.15   is   [0.]\n",
      "27.15   27.69   like   [0.]\n",
      "30.63   30.93   why   [0.]\n",
      "30.96   31.32   is   [0.]\n",
      "31.35   31.74   henry   [1.]\n",
      "31.74   32.28   like   [0.]\n",
      "35.67   35.85   it   [0.]\n",
      "42.12   42.72   ah   [1.]\n",
      "44.19   44.43   it's   [0.]\n",
      "44.43   45.06   good   [1.]\n",
      "45.27   45.42   but   [0.]\n",
      "45.42   45.54   it's   [0.]\n",
      "45.54   45.96   bad   [1.]\n",
      "46.74   46.89   it's   [0.]\n",
      "46.92   47.52   awesome   [1.]\n",
      "48.39   48.57   but   [1.]\n",
      "48.57   48.66   it   [0.]\n",
      "48.66   49.26   sucks   [1.]\n",
      "53.16   53.82   kinda   [0.]\n",
      "55.35   55.5   it's   [0.]\n",
      "55.5   55.83   kinda   [1.]\n",
      "55.83   56.16   hard   [0.]\n",
      "56.16   56.46   to   [0.]\n",
      "56.52   57.03   hum   [1.]\n",
      "58.17   58.59   two   [0.]\n",
      "58.62   59.13   x   [0.]\n",
      "62.31   62.52   a   [0.]\n",
      "62.523259   62.97   two   [0.]\n",
      "63.0   63.48   x   [0.]\n",
      "63.9   64.62   who   [1.]\n",
      "67.32   67.53   two   [0.]\n",
      "67.53   67.95   weeks   [0.]\n",
      "68.07   68.58   plane   [0.]\n",
      "70.35   70.59   it's   [0.]\n",
      "70.59   71.22   like   [0.]\n",
      "74.49   74.76   it   [0.]\n",
      "75.81   76.08   hm   [1.]\n",
      "79.29   79.74   she   [0.]\n",
      "79.77   80.07   she   [0.]\n",
      "82.65   82.92   it   [0.]\n",
      "83.46   83.64   helps   [0.]\n",
      "83.64   84.03   with   [0.]\n",
      "84.749993   85.35   she   [0.]\n",
      "85.92   86.52   she   [0.]\n",
      "87.66   87.9   she   [1.]\n",
      "91.38   92.193735   she   [0.]\n",
      "92.193735   92.43   get   [0.]\n",
      "92.52   92.94   a   [0.]\n",
      "95.73   96.87   she   [0.]\n",
      "96.87   97.29   argued   [0.]\n",
      "99.33   100.56   she   [0.]\n",
      "100.59   101.01   um   [0.]\n",
      "103.38   104.34   she   [0.]\n",
      "104.34   104.52   er   [0.]\n",
      "104.55   105.27   airways   [0.]\n",
      "105.36   105.57   a   [1.]\n",
      "105.87   106.92   loving   [1.]\n",
      "110.82   111.06   which   [0.]\n",
      "111.06   112.23   firm   [0.]\n",
      "112.32   112.68   are   [0.]\n",
      "112.98   113.25   of   [1.]\n",
      "115.44   115.68   of   [1.]\n",
      "116.76   117.03   who   [0.]\n",
      "117.09   117.54   ah   [1.]\n",
      "119.46   119.73   of   [1.]\n",
      "119.76   120.93   who   [0.]\n",
      "123.51   123.78   of   [1.]\n",
      "124.2   124.8   which   [0.]\n",
      "124.8   125.19   makes   [0.]\n",
      "125.22   125.43   a   [0.]\n",
      "125.43   125.64   a   [0.]\n",
      "125.67   126.75   senator   [0.]\n",
      "127.44   127.74   and   [0.]\n",
      "129.72   130.23   and   [0.]\n",
      "130.29   130.44   it   [0.]\n",
      "130.47   130.8   actually   [0.]\n",
      "130.8   131.16   feels   [0.]\n",
      "131.16   131.61   like   [0.]\n",
      "133.77   133.8   i   [1.]\n",
      "133.8   134.52   have   [1.]\n",
      "134.97   135.36   a   [1.]\n",
      "135.96   136.23   match   [0.]\n",
      "136.23   136.29   you   [1.]\n",
      "136.29   136.53   can't   [0.]\n",
      "136.53   136.95   breathe   [0.]\n",
      "137.58   137.849971   if   [0.]\n",
      "142.98   143.16   it   [0.]\n",
      "143.16   143.46   feels   [0.]\n",
      "143.46   143.73   like   [0.]\n",
      "143.73   143.79   you   [0.]\n",
      "143.79   144.18   say   [0.]\n",
      "144.21   144.99   she   [0.]\n",
      "149.31   149.67   ah   [1.]\n",
      "152.19   152.61   ah   [1.]\n",
      "154.23   154.95   some   [0.]\n",
      "154.95   155.85   of   [1.]\n",
      "156.27   156.69   em   [1.]\n",
      "161.34   161.64   it   [0.]\n",
      "161.64   161.91   feels   [0.]\n",
      "161.91   162.81   lights   [1.]\n",
      "165.6   166.8   suzie   [0.]\n",
      "166.8   167.64   factors   [0.]\n",
      "173.94   174.09   huh   [1.]\n",
      "182.28   183.09   as   [1.]\n",
      "183.93   184.56   such   [1.]\n",
      "184.8   185.07   she   [0.]\n",
      "189.06   189.93   us   [0.]\n",
      "190.29   190.709985   only   [0.]\n",
      "190.709985   190.979941   a   [1.]\n",
      "191.55   192.15   roller   [0.]\n",
      "192.15   192.75   coaster   [0.]\n",
      "194.43   195.03   because   [0.]\n",
      "195.06   195.12   i   [1.]\n",
      "195.12   195.54   mean   [0.]\n",
      "200.16   200.28   it   [0.]\n",
      "200.28   200.61   goes   [0.]\n",
      "200.64   201.03   on   [1.]\n",
      "205.41   205.53   it   [0.]\n",
      "205.53   205.8   goes   [0.]\n",
      "205.83   206.19   up   [0.]\n",
      "206.43   206.7   and   [0.]\n",
      "206.7   207.18   down   [0.]\n",
      "207.21   207.42   and   [0.]\n",
      "207.42   207.87   sit   [0.]\n",
      "207.96   208.8   ins   [0.]\n",
      "208.92   209.129766   in   [0.]\n",
      "209.130264   209.4   a   [1.]\n",
      "209.43   211.26   sideways   [0.]\n",
      "211.41   211.83   and   [1.]\n",
      "211.83   212.67   she   [0.]\n",
      "212.76   213.0   and   [0.]\n",
      "213.03   213.78   she   [0.]\n",
      "213.78   213.84   i   [1.]\n",
      "213.84   214.02   don't   [0.]\n",
      "214.02   214.23   really   [0.]\n",
      "214.23   214.68   know   [0.]\n",
      "215.07   215.4   a   [1.]\n",
      "215.43   216.57   fool   [0.]\n",
      "216.66   217.35   of   [1.]\n",
      "219.36   219.78   of   [1.]\n",
      "220.38   221.22   what   [0.]\n",
      "226.74   227.31   of   [0.]\n",
      "227.34   228.24   what   [0.]\n",
      "229.65   230.01   it's   [0.]\n",
      "238.02   238.38   um   [0.]\n",
      "238.92   239.7   what   [0.]\n",
      "239.7   240.0   it's   [0.]\n",
      "241.77   242.04   gonna   [0.]\n",
      "242.04   242.25   be   [0.]\n",
      "242.25   242.76   like   [0.]\n",
      "247.68   247.89   or   [0.]\n",
      "247.89   248.1   when   [0.]\n",
      "248.1   248.46   it's   [0.]\n",
      "250.02   250.32   kind   [0.]\n",
      "250.32   250.38   of   [1.]\n",
      "250.41   250.92   and   [0.]\n",
      "252.87   253.26   in   [0.]\n",
      "253.29   254.25   sun   [0.]\n",
      "254.25   254.94   times   [0.]\n",
      "261.69   261.87   i   [0.]\n",
      "261.87   262.02   can   [0.]\n",
      "262.02   262.26   be   [0.]\n",
      "262.32   263.19   as   [0.]\n",
      "263.25   263.55   a   [1.]\n",
      "264.36   265.26   as   [0.]\n",
      "268.77   269.61   us   [0.]\n",
      "269.7   270.3   harry   [0.]\n",
      "271.32   271.5   i'm   [0.]\n",
      "274.08   274.59   but   [0.]\n",
      "276.42   276.72   but   [1.]\n",
      "277.83   278.13   yes   [0.]\n",
      "278.34   278.76   i'm   [0.]\n",
      "280.32   281.49   us   [0.]\n",
      "283.17   283.53   ah   [1.]\n",
      "284.76   285.21   slut   [0.]\n",
      "285.239971   285.75   some   [0.]\n",
      "285.75   285.96   other   [0.]\n",
      "285.96   286.5   times   [0.]\n",
      "286.74   287.07   me   [0.]\n",
      "287.1   287.4   of   [1.]\n",
      "292.14   292.59   honey   [1.]\n",
      "295.11   295.47   or   [0.]\n",
      "295.71   296.76   she   [0.]\n",
      "299.34   299.67   or   [0.]\n",
      "299.7   301.11   she   [0.]\n",
      "301.11   301.77   amorous   [0.]\n",
      "305.4   305.94   so   [0.]\n",
      "306.39   306.57   i   [0.]\n",
      "306.6   306.84   guess   [0.]\n",
      "306.84   307.05   that's   [0.]\n",
      "307.05   307.38   what   [0.]\n",
      "310.53   310.8   i   [0.]\n",
      "310.83   311.46   myself   [0.]\n",
      "311.46   311.64   would   [0.]\n",
      "311.64   312.69   describes   [0.]\n",
      "313.41   314.07   starring   [0.]\n",
      "314.1   314.4   as   [0.]\n",
      "321.06   321.33   as   [0.]\n",
      "321.33   321.57   being   [0.]\n",
      "321.57   321.99   like   [0.]\n",
      "328.98   329.55   sorry   [0.]\n",
      "332.85   333.42   that   [1.]\n",
      "336.51   336.81   ah   [1.]\n",
      "338.04   338.4   ah   [1.]\n",
      "345.51   345.81   ah   [1.]\n",
      "348.87   349.05   i   [0.]\n",
      "349.05   349.29   can   [0.]\n",
      "349.29   349.5   see   [0.]\n",
      "349.5   350.07   much   [0.]\n",
      "350.58   351.03   i'm   [0.]\n",
      "352.83   353.22   because   [0.]\n",
      "353.22   353.339531   of   [1.]\n",
      "353.34   353.55   it   [0.]\n",
      "356.37   356.73   but   [0.]\n",
      "356.79   356.91   i   [0.]\n",
      "356.91   357.3   hope   [0.]\n",
      "357.42   357.54   it   [0.]\n",
      "357.54   358.05   helped   [0.]\n",
      "358.59   359.07   you   [0.]\n",
      "360.15   360.42   he   [0.]\n",
      "362.7   363.06   she   [0.]\n",
      "363.06   363.27   get   [0.]\n",
      "363.27   363.66   white   [0.]\n",
      "366.03   366.27   it's   [0.]\n",
      "366.27   366.69   like   [0.]\n",
      "370.17   370.71   so   [1.]\n",
      "372.57   372.69   i   [1.]\n",
      "372.69   372.9   hope   [1.]\n",
      "372.9   373.08   that   [1.]\n",
      "373.08   373.53   you   [0.]\n",
      "377.43   377.97   enjoy   [0.]\n",
      "378.0   378.24   be   [0.]\n",
      "378.24   378.51   a   [0.]\n",
      "379.02   379.53   video   [0.]\n",
      "380.31   380.64   in   [0.]\n",
      "380.67   380.79   a   [0.]\n",
      "380.79   382.41   season   [0.]\n",
      "384.27   384.84   and   [1.]\n",
      "385.53   385.89   i   [0.]\n",
      "385.89   386.07   will   [0.]\n",
      "386.85   387.21   say   [0.]\n",
      "387.21   387.63   seen   [0.]\n",
      "389.1   389.82   ah   [1.]\n",
      "391.83   392.01   or   [0.]\n",
      "392.55   392.85   say   [0.]\n",
      "392.85   394.23   yes   [1.]\n"
     ]
    }
   ],
   "source": [
    "for include in cut.include_list:\n",
    "    print(include.start, \" \", include.end, \" \", include.word, \" \", include.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|                                                         | 143/531 [00:00<00:00, 1419.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81 1.05 i'm   [1.]\n",
      "1.05 1.29 hailed   [0.]\n",
      "1.29 1.47 as   [1.]\n",
      "1.47 1.65 it's   [0.]\n",
      "1.68 2.191538 major   [0.]\n",
      "2.191538 2.61 eighty   [0.]\n",
      "3.06 3.42 i'm   [1.]\n",
      "3.42 3.51 i   [1.]\n",
      "3.51 3.63 just   [1.]\n",
      "3.63 3.81 wanted   [0.]\n",
      "3.81 3.87 to   [1.]\n",
      "3.87 4.05 make   [1.]\n",
      "4.05 4.32 this   [0.]\n",
      "4.41 4.62 show   [0.]\n",
      "6.36 6.63 a   [0.]\n",
      "6.66 6.96 short   [0.]\n",
      "6.96 7.11 little   [1.]\n",
      "7.11 7.62 video   [0.]\n",
      "7.65 8.31 i'm   [1.]\n",
      "8.34 8.46 i   [1.]\n",
      "8.46 8.580124 know   [0.]\n",
      "8.580124 8.67 what   [0.]\n",
      "8.67 8.729928 to   [1.]\n",
      "8.729928 8.91 say   [0.]\n",
      "8.91 9.09 that   [0.]\n",
      "9.09 9.36 about   [0.]\n",
      "9.45 9.9 every   [0.]\n",
      "9.9 10.176273 single   [0.]\n",
      "10.176273 10.469998 video   [0.]\n",
      "10.470002 10.71 that   [0.]\n",
      "10.77 11.25 ideal   [0.]\n",
      "12.39 12.72 m   [1.]\n",
      "13.86 14.25 but   [1.]\n",
      "14.34 14.46 i   [1.]\n",
      "14.46 14.73 had   [0.]\n",
      "14.73 15.36 someone   [1.]\n",
      "16.38 16.8 message   [0.]\n",
      "16.8 16.95 me   [0.]\n",
      "16.95 17.07 on   [0.]\n",
      "17.07 17.13 to   [1.]\n",
      "17.13 17.31 you   [0.]\n",
      "17.31 17.79 too   [0.]\n",
      "18.18 18.72 i'm   [1.]\n",
      "19.32 20.07 asking   [0.]\n",
      "20.13 20.67 me   [0.]\n",
      "21.510002 21.75 what   [0.]\n",
      "21.75 21.84 i   [1.]\n",
      "21.84 22.29 did   [0.]\n",
      "22.62 22.89 with   [1.]\n",
      "22.95 23.49 my   [0.]\n",
      "23.52 24.21 blocks   [0.]\n",
      "24.69 25.29 um   [1.]\n",
      "25.62 26.19 and   [0.]\n",
      "26.22 26.4 if   [0.]\n",
      "26.4 26.46 i   [1.]\n",
      "26.46 26.79 talk   [0.]\n",
      "26.97 27.09 on   [1.]\n",
      "27.09 27.18 the   [1.]\n",
      "27.18 27.6 phone   [0.]\n",
      "27.84 28.29 okay   [0.]\n",
      "28.8 28.92 the   [1.]\n",
      "28.92 29.1 first   [0.]\n",
      "29.1 29.25 thing   [0.]\n",
      "29.25 29.4 of   [0.]\n",
      "29.4 29.52 it   [0.]\n",
      "29.52 29.73 too   [0.]\n",
      "29.73 30.06 is   [0.]\n",
      "30.39 31.53 cellphone   [0.]\n",
      "31.59 32.07 i'm   [1.]\n",
      "34.14 34.29 it   [0.]\n",
      "34.29 35.4 depends   [0.]\n",
      "35.49 35.85 on   [0.]\n",
      "35.88 35.94 a   [1.]\n",
      "35.94 36.15 lot   [1.]\n",
      "36.15 36.27 of   [0.]\n",
      "36.27 37.38 circumstances   [0.]\n",
      "37.74 38.25 i'm   [1.]\n",
      "38.31 38.73 with   [1.]\n",
      "38.73 38.82 the   [1.]\n",
      "38.82 39.36 phone   [1.]\n",
      "41.01 41.19 for   [0.]\n",
      "41.19 41.34 me   [0.]\n",
      "41.34 41.43 at   [1.]\n",
      "41.43 41.76 least   [0.]\n",
      "41.79 42.3 i'm   [1.]\n",
      "44.04 44.25 i'll   [1.]\n",
      "44.28 44.58 either   [0.]\n",
      "44.58 45.03 be   [0.]\n",
      "45.72 46.41 extremely   [0.]\n",
      "46.41 47.01 fluent   [0.]\n",
      "48.27 49.23 oars   [0.]\n",
      "49.65 49.98 or   [0.]\n",
      "49.98 50.61 stuttering   [0.]\n",
      "50.64 50.73 a   [1.]\n",
      "50.73 51.24 lot   [0.]\n",
      "52.29 52.5 i'm   [1.]\n",
      "54.06 54.66 and   [0.]\n",
      "54.72 54.84 i   [1.]\n",
      "54.84 55.29 mean   [1.]\n",
      "55.44 55.68 plays   [0.]\n",
      "55.68 55.77 in   [0.]\n",
      "55.77 55.86 the   [1.]\n",
      "55.86 56.28 factor   [0.]\n",
      "56.28 56.49 of   [1.]\n",
      "56.49 56.76 who   [0.]\n",
      "56.76 56.94 i'm   [0.]\n",
      "56.94 57.39 talking   [0.]\n",
      "57.39 57.75 to   [0.]\n",
      "57.78 58.08 how   [0.]\n",
      "58.08 58.65 serious   [0.]\n",
      "58.71 58.86 the   [1.]\n",
      "58.86 59.49 topic   [0.]\n",
      "60.03 60.66 is   [0.]\n",
      "60.69 61.47 i'm   [1.]\n",
      "62.58 63.21 how   [0.]\n",
      "64.26 64.56 feeling   [0.]\n",
      "64.56 64.74 that   [0.]\n",
      "64.74 65.19 day   [0.]\n",
      "65.91 66.24 there's   [0.]\n",
      "66.3 66.39 a   [1.]\n",
      "66.39 66.54 lot   [0.]\n",
      "66.54 66.66 of   [1.]\n",
      "66.66 66.93 different   [0.]\n",
      "66.93 67.65 factors   [0.]\n",
      "67.98 68.34 and   [0.]\n",
      "68.34 68.43 it   [0.]\n",
      "68.43 68.85 goes   [0.]\n",
      "69.12 69.39 to   [0.]\n",
      "69.42 70.17 calling   [0.]\n",
      "70.62 71.22 i'm   [1.]\n",
      "73.47 73.95 nah   [1.]\n",
      "75.21 75.78 wall   [0.]\n",
      "76.32 76.8 talking   [0.]\n",
      "76.8 77.22 with   [1.]\n",
      "77.7 77.91 a   [0.]\n",
      "77.94 78.51 speech   [0.]\n",
      "78.54 79.11 impediment   [0.]\n",
      "79.8 80.1 so   [0.]\n",
      "80.1 80.7 i'm   [1.]\n",
      "81.54 81.75 so   [0.]\n",
      "81.75 82.02 yeah   [0.]\n",
      "82.02 82.32 i'm   [0.]\n",
      "82.32 82.44 if   [1.]\n",
      "82.44 82.62 that   [0.]\n",
      "82.62 83.13 answers   [0.]\n",
      "83.19 83.4 that   [0.]\n",
      "83.4 83.88 question   [0.]\n",
      "83.91 84.42 i'm   [1.]\n",
      "85.8 86.13 and   [1.]\n",
      "86.37 86.55 that's   [0.]\n",
      "86.55 86.7 how   [0.]\n",
      "86.7 86.79 i   [0.]\n",
      "86.79 86.97 am   [0.]\n",
      "86.97 87.09 on   [1.]\n",
      "87.09 87.15 the   [1.]\n",
      "87.15 87.57 phone   [1.]\n",
      "87.69 88.41 i'm   [1.]\n",
      "89.22 89.43 and   [0.]\n",
      "89.43 89.61 i'm   [0.]\n",
      "89.61 89.79 really   [0.]\n",
      "89.82 91.83 surprisingly   [0.]\n",
      "92.34 92.61 pretty   [0.]\n",
      "92.61 93.15 fluid   [1.]\n",
      "93.15 93.36 right   [0.]\n",
      "93.36 93.72 now   [0.]\n",
      "93.99 94.17 kind   [0.]\n",
      "94.17 94.26 of   [1.]\n",
      "94.26 94.53 weird   [1.]\n",
      "95.1 95.4 shoot   [0.]\n",
      "96.81 97.08 i've   [1.]\n",
      "97.08 97.35 actually   [0.]\n",
      "97.35 97.68 been   [1.]\n",
      "98.13 98.46 really   [1.]\n",
      "98.46 98.79 swim   [1.]\n",
      "98.79 99.03 in   [1.]\n",
      "99.06 99.3 this   [1.]\n",
      "99.33 99.78 past   [1.]\n",
      "99.78 100.05 week   [0.]\n",
      "100.05 100.11 or   [1.]\n",
      "100.11 100.62 so   [0.]\n",
      "100.65 100.8 which   [0.]\n",
      "100.8 100.92 is   [1.]\n",
      "100.92 101.22 actually   [0.]\n",
      "101.22 101.49 kind   [1.]\n",
      "101.49 101.58 of   [1.]\n",
      "101.58 102.0 weird   [0.]\n",
      "102.54 102.69 huh   [1.]\n",
      "103.05 103.92 considering   [0.]\n",
      "104.13 104.46 last   [0.]\n",
      "104.46 104.64 week   [0.]\n",
      "104.64 104.7 it   [1.]\n",
      "104.7 104.82 was   [1.]\n",
      "104.82 104.91 my   [0.]\n",
      "104.91 105.18 first   [0.]\n",
      "105.39 106.23 school   [0.]\n",
      "106.77 106.89 when   [1.]\n",
      "106.89 106.949451 i   [1.]\n",
      "106.95 107.04 was   [0.]\n",
      "107.04 107.16 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|                                  | 298/531 [00:00<00:00, 836.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in   [1.]\n",
      "107.160549 107.37 so   [0.]\n",
      "107.37 107.73 excited   [0.]\n",
      "107.73 107.91 for   [0.]\n",
      "107.91 108.0 it   [0.]\n",
      "108.0 108.09 at   [0.]\n",
      "108.09 108.42 all   [1.]\n",
      "109.77 109.98 but   [0.]\n",
      "109.98 110.4 um   [1.]\n",
      "111.33 111.78 and   [0.]\n",
      "111.84 112.2 then   [1.]\n",
      "112.2 112.29 the   [0.]\n",
      "112.29 112.47 other   [1.]\n",
      "112.47 112.89 thing   [0.]\n",
      "113.31 113.94 i'm   [1.]\n",
      "114.12 114.33 that   [0.]\n",
      "114.33 114.48 they   [0.]\n",
      "114.48 114.81 said   [0.]\n",
      "114.81 114.93 they   [0.]\n",
      "114.93 115.2 talked   [0.]\n",
      "115.2 115.83 about   [0.]\n",
      "116.97 117.54 chemistry   [0.]\n",
      "118.23 118.41 my   [0.]\n",
      "118.41 119.16 blocks   [0.]\n",
      "120.24 120.48 big   [0.]\n",
      "120.48 120.78 field   [0.]\n",
      "120.78 120.9 is   [0.]\n",
      "120.900117 121.11 talk   [0.]\n",
      "121.11 121.41 about   [0.]\n",
      "122.43 122.73 walks   [0.]\n",
      "122.76 123.27 way   [0.]\n",
      "125.01 125.13 i   [1.]\n",
      "125.13 125.58 have   [0.]\n",
      "125.58 125.76 done   [0.]\n",
      "125.76 125.85 in   [1.]\n",
      "125.85 125.94 the   [1.]\n",
      "125.94 126.48 past   [1.]\n",
      "126.81 126.93 you   [0.]\n",
      "126.93 127.05 can   [0.]\n",
      "127.05 127.315503 see   [0.]\n",
      "127.35 127.71 in   [0.]\n",
      "127.74 128.1 my   [0.]\n",
      "128.1 128.34 older   [0.]\n",
      "128.34 129.24 videos   [0.]\n",
      "129.3 129.57 when   [0.]\n",
      "129.6 129.78 i   [0.]\n",
      "130.02 130.44 entered   [0.]\n",
      "130.44 130.62 like   [0.]\n",
      "130.62 130.71 as   [0.]\n",
      "130.71 130.92 soon   [0.]\n",
      "130.92 131.07 as   [0.]\n",
      "131.07 131.25 i   [0.]\n",
      "131.28 131.46 be   [0.]\n",
      "131.46 132.12 inspiring   [0.]\n",
      "132.12 132.27 as   [0.]\n",
      "132.27 132.51 they   [0.]\n",
      "133.08 133.41 shoot   [0.]\n",
      "133.47 133.98 i'm   [1.]\n",
      "134.73 135.06 anna   [0.]\n",
      "135.06 135.528823 sylvia   [0.]\n",
      "135.603516 135.93 now   [0.]\n",
      "135.93 136.62 sometimes   [0.]\n",
      "136.65 136.8 i'm   [0.]\n",
      "136.8 136.92 not   [1.]\n",
      "136.92 137.07 really   [0.]\n",
      "137.07 137.34 sure   [0.]\n",
      "137.34 137.49 where   [0.]\n",
      "137.49 137.76 where   [0.]\n",
      "137.76 138.06 where   [0.]\n",
      "138.18 138.42 that   [0.]\n",
      "138.42 138.63 came   [0.]\n",
      "138.63 138.84 from   [0.]\n",
      "138.84 138.96 or   [0.]\n",
      "138.96 139.2 where   [0.]\n",
      "139.2 139.53 that   [0.]\n",
      "141.69 142.11 yeah   [0.]\n",
      "142.71 143.1 where   [0.]\n",
      "143.1 143.16 it   [1.]\n",
      "143.16 143.37 came   [0.]\n",
      "143.37 143.67 from   [0.]\n",
      "143.73 144.24 i'm   [1.]\n",
      "145.83 146.22 i'm   [1.]\n",
      "146.67 146.88 just   [0.]\n",
      "146.88 147.06 one   [0.]\n",
      "147.06 147.413437 day   [0.]\n",
      "147.42 147.54 of   [0.]\n",
      "147.54 147.75 just   [0.]\n",
      "147.75 148.05 started   [0.]\n",
      "148.05 148.35 doing   [0.]\n",
      "148.35 148.53 it   [0.]\n",
      "149.13 149.4 now   [0.]\n",
      "149.4 149.46 i   [1.]\n",
      "149.46 149.64 don't   [0.]\n",
      "149.64 149.82 really   [0.]\n",
      "149.82 149.960112 do   [0.]\n",
      "149.979888 150.12 as   [0.]\n",
      "150.12 150.33 much   [0.]\n",
      "150.84 151.14 as   [0.]\n",
      "151.17 151.26 i   [1.]\n",
      "151.26 151.56 do   [0.]\n",
      "151.59 151.98 i'm   [1.]\n",
      "152.07 152.4 now   [0.]\n",
      "152.4 152.61 live   [0.]\n",
      "152.61 152.76 in   [0.]\n",
      "153.81 153.99 like   [1.]\n",
      "153.99 154.17 when   [1.]\n",
      "154.17 154.5 i'm   [1.]\n",
      "154.83 155.01 in   [0.]\n",
      "155.01 155.34 surrey   [0.]\n",
      "155.34 155.46 know   [0.]\n",
      "155.46 155.85 why   [0.]\n",
      "155.91 156.48 i'm   [1.]\n",
      "157.23 157.32 i   [1.]\n",
      "157.32 157.5 just   [0.]\n",
      "158.88 159.06 i   [0.]\n",
      "159.06 159.33 just   [0.]\n",
      "159.33 159.84 quit   [1.]\n",
      "159.87 160.37584 seen   [0.]\n",
      "160.37584 160.65 it   [1.]\n",
      "160.8 161.01 so   [0.]\n",
      "161.01 161.070015 it   [1.]\n",
      "161.070015 161.25 don't   [0.]\n",
      "161.94 162.33 shoot   [0.]\n",
      "162.48 162.69 so   [0.]\n",
      "162.69 162.75 i   [1.]\n",
      "162.75 162.96 don't   [0.]\n",
      "163.14 163.32 hurt   [1.]\n",
      "163.32 163.56 her   [0.]\n",
      "164.67 165.27 um   [1.]\n",
      "166.44 167.13 and   [0.]\n",
      "167.22 167.31 i   [1.]\n",
      "167.31 167.52 would   [1.]\n",
      "167.52 167.85 re   [0.]\n",
      "167.85 168.15 say   [0.]\n",
      "168.15 168.39 it   [1.]\n",
      "168.57 168.87 i'm   [0.]\n",
      "168.87 169.11 just   [0.]\n",
      "169.11 169.41 to   [1.]\n",
      "169.65 169.89 catch   [0.]\n",
      "169.89 170.46 myself   [0.]\n",
      "171.06 171.6 hand   [0.]\n",
      "171.656309 171.778696 and   [1.]\n",
      "171.78 171.96 other   [1.]\n",
      "171.96 172.17 weird   [0.]\n",
      "172.17 172.38 thing   [0.]\n",
      "172.38 172.5 i've   [1.]\n",
      "172.5 172.62 been   [1.]\n",
      "172.62 172.95 doing   [0.]\n",
      "172.95 173.52 recently   [0.]\n",
      "173.61 173.73 i'm   [1.]\n",
      "173.73 173.88 not   [1.]\n",
      "173.88 174.45 sure   [0.]\n",
      "174.63 174.93 where   [0.]\n",
      "174.93 175.08 this   [0.]\n",
      "175.08 175.29 came   [0.]\n",
      "175.29 175.709985 from   [0.]\n",
      "175.74 176.13 italy   [0.]\n",
      "177.54 177.9 she   [0.]\n",
      "179.97 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|                   | 398/531 [00:00<00:00, 735.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180.12 a   [1.]\n",
      "180.12 180.45 feeling   [1.]\n",
      "180.78 181.05 taking   [0.]\n",
      "181.05 181.17 my   [0.]\n",
      "181.17 181.56 tongue   [0.]\n",
      "181.56 182.01 l   [1.]\n",
      "182.76 183.45 a   [1.]\n",
      "184.74 184.83 i   [1.]\n",
      "184.83 184.95 don't   [1.]\n",
      "184.95 185.16 really   [0.]\n",
      "185.16 185.34 know   [0.]\n",
      "185.34 185.91 why   [0.]\n",
      "186.84 186.93 i   [1.]\n",
      "186.93 187.02 don't   [1.]\n",
      "187.02 187.17 really   [0.]\n",
      "187.17 187.29 know   [0.]\n",
      "187.29 187.62 where   [1.]\n",
      "187.8 188.16 where   [0.]\n",
      "188.16 188.25 that   [1.]\n",
      "188.25 188.52 came   [0.]\n",
      "188.52 188.91 from   [1.]\n",
      "190.47 190.768594 cal   [0.]\n",
      "190.768594 191.34 works   [0.]\n",
      "191.37 192.06 so   [0.]\n",
      "192.93 193.11 kind   [0.]\n",
      "193.11 193.17 of   [1.]\n",
      "193.17 193.44 helps   [0.]\n",
      "193.44 193.8 me   [0.]\n",
      "193.83 194.37 i'm   [1.]\n",
      "194.4 194.61 with   [0.]\n",
      "194.61 195.3 blocking   [0.]\n",
      "198.54 199.05 and   [0.]\n",
      "200.52 201.0 i'm   [1.]\n",
      "201.72 202.23 i'm   [0.]\n",
      "204.06 204.33 i   [1.]\n",
      "204.33 204.54 know   [0.]\n",
      "204.54 204.69 this   [0.]\n",
      "204.69 204.81 is   [1.]\n",
      "204.81 204.93 a   [1.]\n",
      "204.96 205.26 quick   [0.]\n",
      "205.53 206.07 random   [0.]\n",
      "206.19 206.55 level   [1.]\n",
      "206.55 207.06 video   [0.]\n",
      "208.8 208.83 i   [1.]\n",
      "208.83 209.04 plan   [1.]\n",
      "209.04 209.13 on   [1.]\n",
      "209.13 209.55 making   [1.]\n",
      "209.58 209.85 more   [0.]\n",
      "209.85 210.48 videos   [1.]\n",
      "211.17 211.47 this   [0.]\n",
      "211.47 211.95 week   [0.]\n",
      "212.04 212.64 are   [1.]\n",
      "213.27 213.54 with   [1.]\n",
      "213.57 214.26 tommy   [0.]\n",
      "215.22 215.76 i'm   [1.]\n",
      "216.6 216.84 not   [0.]\n",
      "216.84 217.08 until   [1.]\n",
      "217.08 217.23 you   [0.]\n",
      "217.23 217.59 will   [0.]\n",
      "217.59 217.74 have   [1.]\n",
      "217.74 217.83 you   [0.]\n",
      "217.83 218.07 already   [0.]\n",
      "218.07 218.31 hit   [1.]\n",
      "218.34 218.7 by   [0.]\n",
      "218.79 219.030103 a   [1.]\n",
      "219.06 219.24 v   [0.]\n",
      "219.24 219.84 guys   [0.]\n",
      "220.29 220.68 might   [0.]\n",
      "220.68 221.04 enjoy   [0.]\n",
      "221.04 221.31 them   [1.]\n",
      "221.34 221.61 might   [0.]\n",
      "221.61 221.91 not   [1.]\n",
      "221.91 222.03 i   [0.]\n",
      "222.03 222.54 really   [0.]\n",
      "222.54 222.75 don't   [0.]\n",
      "222.75 223.2 know   [0.]\n",
      "223.38 223.68 these   [0.]\n",
      "223.68 223.95 two   [0.]\n",
      "223.98 224.34 videos   [0.]\n",
      "224.34 224.46 that   [0.]\n",
      "224.46 224.61 were   [0.]\n",
      "224.61 224.7 to   [0.]\n",
      "224.7 224.938857 make   [0.]\n",
      "226.89 227.19 shoot   [0.]\n",
      "227.28 227.55 arcs   [0.]\n",
      "227.55 227.73 and   [0.]\n",
      "227.73 227.88 be   [0.]\n",
      "227.88 228.24 really   [0.]\n",
      "228.24 228.9 different   [0.]\n",
      "229.62 229.95 so   [0.]\n",
      "229.95 230.01 i   [1.]\n",
      "230.01 230.16 don't   [1.]\n",
      "230.16 230.43 know   [0.]\n",
      "230.43 230.580571 if   [0.]\n",
      "230.580571 230.640747 you   [1.]\n",
      "230.640747 230.759956 can   [0.]\n",
      "230.759956 231.33 flail   [0.]\n",
      "231.39 231.93 i'm   [1.]\n",
      "232.8 232.95 a   [0.]\n",
      "232.95 233.22 yeah   [0.]\n",
      "233.22 233.76 i'm   [0.]\n",
      "234.51 234.69 a   [0.]\n",
      "234.69 235.11 lease   [1.]\n",
      "235.23 235.41 fee   [0.]\n",
      "235.41 235.62 as   [1.]\n",
      "235.62 235.8 like   [0.]\n",
      "235.8 235.89 the   [1.]\n",
      "235.89 236.4 video   [0.]\n",
      "236.46 237.0 i'm   [1.]\n",
      "237.45 237.78 like   [0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 531/531 [00:00<00:00, 785.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237.78 238.02 it   [0.]\n",
      "239.19 240.06 comment   [0.]\n",
      "240.81 241.17 comment   [0.]\n",
      "241.17 241.32 what   [0.]\n",
      "241.32 241.44 you   [0.]\n",
      "241.74 242.01 want   [0.]\n",
      "242.01 242.1 to   [0.]\n",
      "242.1 242.31 see   [0.]\n",
      "242.31 242.64 next   [0.]\n",
      "242.64 242.82 door   [0.]\n",
      "242.82 242.91 if   [0.]\n",
      "242.91 243.0 you   [0.]\n",
      "243.0 243.18 have   [0.]\n",
      "243.18 243.33 any   [1.]\n",
      "243.33 244.02 questions   [0.]\n",
      "244.68 245.04 about   [0.]\n",
      "245.49 245.97 entering   [0.]\n",
      "246.63 247.17 or   [0.]\n",
      "247.2 247.5 about   [0.]\n",
      "247.5 247.71 my   [0.]\n",
      "247.71 248.76 experiences   [0.]\n",
      "248.76 248.97 with   [1.]\n",
      "248.97 249.12 it   [1.]\n",
      "249.15 249.63 i'm   [1.]\n",
      "250.38 251.01 orders   [0.]\n",
      "251.49 252.15 ideas   [0.]\n",
      "252.15 252.3 for   [0.]\n",
      "252.3 252.54 pretty   [0.]\n",
      "252.54 252.9 much   [0.]\n",
      "253.05 253.23 any   [0.]\n",
      "253.23 253.65 video   [0.]\n",
      "253.68 253.95 i'm   [0.]\n",
      "253.95 254.16 just   [0.]\n",
      "254.19 254.55 laid   [0.]\n",
      "254.58 254.82 down   [0.]\n",
      "254.85 254.97 in   [0.]\n",
      "254.97 255.06 the   [1.]\n",
      "255.06 255.6 comments   [0.]\n",
      "255.9 256.5 below   [0.]\n",
      "257.1 257.73 um   [1.]\n",
      "260.97 261.36 yeah   [0.]\n",
      "261.36 261.81 i'm   [1.]\n",
      "262.92 263.43 share   [0.]\n",
      "263.43 263.58 with   [1.]\n",
      "263.58 263.67 your   [1.]\n",
      "263.67 264.36 friends   [0.]\n",
      "264.42 264.78 all   [0.]\n",
      "264.78 265.2 that   [0.]\n",
      "265.86 266.13 what   [0.]\n",
      "266.13 266.49 not   [0.]\n",
      "267.87 268.02 to   [0.]\n",
      "268.02 268.2 read   [0.]\n",
      "268.2 268.59 easily   [0.]\n",
      "268.59 268.86 say   [0.]\n",
      "268.86 269.07 to   [0.]\n",
      "269.340117 270.36 themselves   [0.]\n",
      "270.93 271.56 um   [1.]\n",
      "272.67 272.91 so   [0.]\n",
      "272.91 273.15 yeah   [0.]\n",
      "273.45 273.54 we'll   [0.]\n",
      "273.54 273.96 see   [0.]\n",
      "273.99 274.23 in   [0.]\n",
      "274.32 274.439971 that   [1.]\n",
      "274.439971 274.83 actually   [0.]\n",
      "275.34 275.729619 see   [0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(cut.df.index[:]):\n",
    "    print(cut.df['start'][i],cut.df['end'][i],cut.df['word'][i],\" \",np.round(cut.predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut.generate_complex_filter(cut.render_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for render in cut.render_list:\n",
    "    print(render.start, \" \", render.end, \" \", render.word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for render in render_list:\n",
    "    print(render.start, \" \", render.end, \" \", render.word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conf</th>\n",
       "      <th>end</th>\n",
       "      <th>start</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.767439</td>\n",
       "      <td>1.230000</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>hey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.767439</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>1.230000</td>\n",
       "      <td>guys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>it's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.191272</td>\n",
       "      <td>1.680000</td>\n",
       "      <td>major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.901827</td>\n",
       "      <td>2.580000</td>\n",
       "      <td>2.191272</td>\n",
       "      <td>eighty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>0.993181</td>\n",
       "      <td>274.230000</td>\n",
       "      <td>273.990000</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>0.997430</td>\n",
       "      <td>274.439971</td>\n",
       "      <td>274.320000</td>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>0.999491</td>\n",
       "      <td>274.890000</td>\n",
       "      <td>274.439971</td>\n",
       "      <td>actually</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>0.998176</td>\n",
       "      <td>274.920000</td>\n",
       "      <td>274.890000</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>0.999980</td>\n",
       "      <td>275.730000</td>\n",
       "      <td>275.340000</td>\n",
       "      <td>see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>535 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         conf         end       start      word\n",
       "0    0.767439    1.230000    1.050000       hey\n",
       "1    0.767439    1.470000    1.230000      guys\n",
       "2    1.000000    1.650000    1.470000      it's\n",
       "3    1.000000    2.191272    1.680000     major\n",
       "4    0.901827    2.580000    2.191272    eighty\n",
       "..        ...         ...         ...       ...\n",
       "530  0.993181  274.230000  273.990000        in\n",
       "531  0.997430  274.439971  274.320000      that\n",
       "532  0.999491  274.890000  274.439971  actually\n",
       "533  0.998176  274.920000  274.890000         i\n",
       "534  0.999980  275.730000  275.340000       see\n",
       "\n",
       "[535 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut.df\n",
    "# cut.df.to_csv('now.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Bellow is Process by Using vosk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|                                                                                 | 6/535 [00:00<00:09, 56.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting feature...\n",
      "Object created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|                                                  | 195/535 [00:02<00:03, 88.84it/s]C:\\Users\\mingb\\anaconda3\\envs\\pythonGPU\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=950\n",
      "  warnings.warn(\n",
      " 62%|                              | 334/535 [00:03<00:02, 87.25it/s]C:\\Users\\mingb\\anaconda3\\envs\\pythonGPU\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1944\n",
      "  warnings.warn(\n",
      " 84%|             | 448/535 [00:05<00:00, 96.32it/s]C:\\Users\\mingb\\anaconda3\\envs\\pythonGPU\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=964\n",
      "  warnings.warn(\n",
      "100%|| 535/535 [00:05<00:00, 89.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved features to sbcon_feature.csv\n",
      "Load feature from sbcon_feature.csv\n",
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 535/535 [00:00<00:00, 10518.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish predict!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process by using vosk\n",
    "\n",
    "model = tf.keras.models.load_model('Model/newmodel/20201227-1123-MLP-RMSprop-Default-80-123.h5')\n",
    "feature_file = f'{cut.FILENAME}_feature.csv'\n",
    "df = cut.df\n",
    "sampleRate = cut.sampleRate\n",
    "fail_list = []\n",
    "time_margin = int( (  (1/cut.FRAME_RATE) *cut.FRAME_MARGIN ) )\n",
    "index_margin = int( (  (1/cut.FRAME_RATE) *cut.FRAME_MARGIN ) *cut.sampleRate )\n",
    "\n",
    "if(os.path.exists(feature_file)):\n",
    "    os.remove(feature_file)\n",
    "\n",
    "if(not os.path.exists(feature_file)):\n",
    "    print(\"Extracting feature...\")\n",
    "    features = np.empty(shape=(0,80))\n",
    "    ds = Dataset()\n",
    "    for i in tqdm(cut.df.index[:]): \n",
    "#         start_index = int(df['start'][i] * sampleRate)\n",
    "#         end_index = int(df['end'][i] * sampleRate)\n",
    "        start_index = max(0, int(  df['start'][i] * cut.sampleRate))\n",
    "        end_index = min( int( (df['end'][i]) * cut.sampleRate), cut.audioSampleCount)\n",
    "#         print(start_index,\" \",end_index)\n",
    "#         try:\n",
    "        fea = ds.get_feature_by_audio(cut.audioData[start_index:end_index],11025)\n",
    "        features = np.vstack((features,[fea]))\n",
    "#         except:\n",
    "#             ts = Timestamp(df['start'][i],df['end'][i],word=df['word'][i])\n",
    "#             fail_list.append(ts)\n",
    "#             print('Failed index:',i)\n",
    "    print(f'Saved features to {feature_file}')\n",
    "    np.savetxt(feature_file, features, delimiter=',')\n",
    "\n",
    "    \n",
    "print(f'Load feature from {feature_file}')\n",
    "features = np.loadtxt(feature_file,delimiter=',')\n",
    "\n",
    "print('Predicting...')\n",
    "predictions = model.predict(x=features, batch_size=84,verbose=0)\n",
    "print(\"Finish predict!\")\n",
    "\n",
    "\n",
    "include_list = []\n",
    "for i in tqdm(cut.df.index[:]):\n",
    "    isInclude = True\n",
    "    predict = np.round(predictions[i])\n",
    "    word = df['word'][i]\n",
    "    if(word == \"i'm\" or word == 'um' or word =='m'):\n",
    "        if(predict == 1):\n",
    "            isInclude = False\n",
    "    if(isInclude):\n",
    "        start = df['start'][i]\n",
    "        end = df['end'][i]\n",
    "        ts = Timestamp(start,end,word=word,label=predict)\n",
    "        include_list.append(ts)\n",
    "#     print(df['word'][i],' ',np.round(predictions[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(df.index[:]):\n",
    "    print(df['start'][i],df['end'][i],df['word'][i],\" \",np.round(predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_list = []\n",
    "counter = 0\n",
    "start = include_list[0].start\n",
    "end = include_list[0].end\n",
    "word = \"\"\n",
    "for i,ts in tqdm(enumerate(include_list)):\n",
    "    current_start = ts.start\n",
    "    current_end = ts.end\n",
    "    prev_start = include_list[i-1].start\n",
    "    prev_end = include_list[i-1].end\n",
    "    if(i >= 1 and current_start != prev_end):\n",
    "        segment = Timestamp(start,prev_end, word=word)\n",
    "        word = ''\n",
    "        start = current_start\n",
    "        render_list.append(segment)\n",
    "        counter = counter + 1\n",
    "    word = word + ts.word + \" \"\n",
    "    print(segment.start, \" \", segment.end,\" \", segment.word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim = []\n",
    "duration_list = []\n",
    "number_of_segment = 0\n",
    "prev = 0\n",
    "current = 0\n",
    "\n",
    "# with out xfade\n",
    "for ts in render_list:\n",
    "    duration_list.append(ts.end-ts.start)\n",
    "    trim.append(\n",
    "        f'[0:v]trim=start={ts.start}:end={ts.end},setpts=PTS-STARTPTS[v{number_of_segment}]')\n",
    "    trim.append(\n",
    "        f'[0:a]atrim=start={ts.start}:end={ts.end},asetpts=PTS-STARTPTS[a{number_of_segment}]')\n",
    "    number_of_segment += 1\n",
    "    \n",
    "filter = ';'.join(trim)\n",
    "filter = filter + \";\"\n",
    "\n",
    "# Normal cut feature\n",
    "for i in range(number_of_segment):\n",
    "    filter += f' [v{i}] [a{i}]'\n",
    "    \n",
    "    \n",
    "# Start to generate ending of command\n",
    "filter += f'concat=n={number_of_segment}:v=1:a=1 [out]'\n",
    "filter = '\"' + filter + '\"'\n",
    "filter = f'ffmpeg -y -i {cut.INPUT_FILE} -filter_complex ' + filter\n",
    "filter = filter + f' -map \"[out]\" {cut.FILENAME}_COMPLEX.mp4'\n",
    "bat_path = cut.write_to_bat(filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ts in include_list:\n",
    "    print(ts.start, \" \", ts.end,\" \",ts.word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ts in include_list:\n",
    "#     newstart = max(0,   (ts.start - frame_margin) )\n",
    "#     newend = min(  (ts.end + frame_margin), (cut.audioSampleCount/cut.sampleRate) )\n",
    "#     ts.start = newstart\n",
    "#     ts.end = newend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2133\n",
      "0.13333333333333333\n"
     ]
    }
   ],
   "source": [
    "# index_margin = int( (  (1/cut.FRAME_RATE) *4 ) *cut.sampleRate )\n",
    "# start_index = max(0, int(  df['start'][0] * cut.sampleRate - index_margin))\n",
    "# end_index = min( int( (df['end'][0]) * cut.sampleRate + index_margin), cut.audioSampleCount)\n",
    "# print(df['start'][0], \" \",start_index)\n",
    "# print(df['end'][0], \" \",end_index)\n",
    "# print(index_margin)\n",
    "\n",
    "# frame_margin = ( (1/cut.FRAME_RATE) *cut.FRAME_MARGIN )\n",
    "# index_margin = int( (  (1/cut.FRAME_RATE) *cut.FRAME_MARGIN ) *cut.sampleRate )\n",
    "# print(index_margin)\n",
    "# print(frame_margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ts in include_list:\n",
    "#     newstart = max(0,   (ts.start - frame_margin) )\n",
    "#     newend = min(  (ts.end + frame_margin), (cut.audioSampleCount/cut.sampleRate) )\n",
    "#     ts.start = newstart\n",
    "#     ts.end = newend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/keras-team/keras/issues/14040\n",
    "KeyError: 'sample_weight_mode'\n",
    "\"pip install --upgrade tesorflow --user\n",
    "Then restart the kernal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "librosa change log\n",
    "\n",
    "https://stackoverflow.com/questions/63997969/attributeerror-module-librosa-has-no-attribute-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1383\n",
      "1970\n",
      "136\n",
      "16000\n"
     ]
    }
   ],
   "source": [
    "#overlap technique\n",
    "\n",
    "\n",
    "# print(len(cut.isInclude))\n",
    "# print(len(cut.hop_list))\n",
    "# print(len(cut.ts_list_index))\n",
    "# print(cut.sampleRate)\n",
    "# for ts in cut.ts_list_index:\n",
    "#     print(ts.start,\" \",ts.end, ((ts.end-ts.start)/cut.sampleRate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@vvk.victory/audio-processing-librosa-split-on-silence-8e1edab07bbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_words(res):\n",
    "#     jres = json.loads(res)\n",
    "#     if not 'result' in jres:\n",
    "#         return []\n",
    "#     words = jres['result']\n",
    "#     return words\n",
    "\n",
    "# def transcribe_words(recognizer, bytes):\n",
    "#     results = []\n",
    "\n",
    "#     chunk_size = 4000\n",
    "#     for chunk_no in range(math.ceil(len(bytes)/chunk_size)):\n",
    "#         start = chunk_no*chunk_size\n",
    "#         end = min(len(bytes), (chunk_no+1)*chunk_size)\n",
    "#         data = bytes[start:end]\n",
    "\n",
    "#         if recognizer.AcceptWaveform(data):\n",
    "#             words = extract_words(recognizer.Result())\n",
    "#             results += words\n",
    "#     results += extract_words(recognizer.FinalResult())\n",
    "\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# start_time = time.time()\n",
    "# vosk.SetLogLevel(-1)\n",
    "# ts = cut.ts_list_index[10]\n",
    "# start = ts.start\n",
    "# end = ts.end\n",
    "# int16 = np.int16(cut.audioData * 32768).tobytes()\n",
    "# model_path='vosk-model-en-us-aspire-0.2'\n",
    "# model = vosk.Model(model_path)\n",
    "# recognizer = vosk.KaldiRecognizer(model, 16000)\n",
    "# res = transcribe_words(recognizer, int16)\n",
    "# df = pandas.DataFrame.from_records(res)\n",
    "# df = df.sort_values('start')\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ts.start)\n",
    "# print(ts.end)\n",
    "# print(((df['start'][0]*16000)+(ts.start))/ cut.sampleRate)\n",
    "# print((df['end'][0]*16000)+(ts.end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_path='sbcon-filtered.csv'\n",
    "# df.to_csv(out_path, index=False)\n",
    "# print('Word segments saved to', out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another possible transcribe: kaldi\n",
    "\n",
    "https://github.com/gooofy/py-kaldi-asr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible transcribe alternative: pocketsphinx\n",
    "Reason not to use: is very hard to use and low accuracy\n",
    "Possbile problem: the framerate doenst match with the model\n",
    "https://stackoverflow.com/questions/64153590/audio-signal-split-at-word-level-boundary\n",
    "\n",
    "https://stackoverflow.com/questions/38808776/python-pocketsphinx-recognition-from-the-microphone\n",
    "\n",
    "https://github.com/cmusphinx/pocketsphinx-python/blob/dfca2739c7a32dd474c425dad1cf87c1d6e1a316/readme.md\n",
    "\n",
    "Solved cant install pyaudio\n",
    "https://stackoverflow.com/questions/52283840/i-cant-install-pyaudio-on-windows-how-to-solve-error-microsoft-visual-c-14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ, path\n",
    "import pyaudio\n",
    "import wave\n",
    "import sys\n",
    "\n",
    "from pocketsphinx.pocketsphinx import *\n",
    "from sphinxbase.sphinxbase import *\n",
    "from pocketsphinx import get_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(path.join(MODELDIR, 'en-us.lm.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = Decoder.default_config()\n",
    "# MODELDIR= get_model_path()\n",
    "# config.set_string('-hmm', path.join(MODELDIR, 'en-us'))\n",
    "# config.set_string('-lm', path.join(MODELDIR, 'en-us.lm.bin'))\n",
    "# config.set_string('-dict', path.join(MODELDIR, 'cmudict-en-us.dict'))\n",
    "# decoder = Decoder(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # stream = open('sbcon-1.wav', 'rb')\n",
    "# # p = pyaudio.PyAudio()\n",
    "# # stream = p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=1024)\n",
    "# # stream.start_stream() \n",
    "# wf = wave.open('sbcon-1.wav', 'rb')\n",
    "\n",
    "# stream = p.open(format =\n",
    "#                 p.get_format_from_width(wf.getsampwidth()),\n",
    "#                 channels = 1,\n",
    "#                 rate = 16000,\n",
    "#                 input = True,\n",
    "#                frames_per_buffer=1024)\n",
    "# stream.start_stream() \n",
    "# decoder.start_utt()\n",
    "# while True:\n",
    "#     buf = stream.read(1024)\n",
    "#     if buf:\n",
    "#         decoder.process_raw(buf, False, False)\n",
    "#     else:\n",
    "#         break\n",
    "# decoder.end_utt()\n",
    "# print ('Best hypothesis segments: ', [seg.word for seg in decoder.seg()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/58841039/i-think-librosa-effect-split-has-some-problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = cut.audioData\n",
    "# y=librosa.amplitude_to_db(abs(x))\n",
    "# # short time fourier transform\n",
    "# # (n_fft and hop length determine frequency/time resolution)\n",
    "# n_fft = 2048\n",
    "# S = librosa.stft(x, n_fft=n_fft, hop_length=n_fft//2)\n",
    "# print(S.shape)\n",
    "# # convert to db\n",
    "# D = librosa.amplitude_to_db(np.abs(S), ref=np.max)\n",
    "# top_db = np.max(abs(D)) * 0.3\n",
    "# print(np.max(abs(D)))\n",
    "# nonMuteSections = librosa.effects.split(x,top_db=top_db, ref=np.max)\n",
    "# print(nonMuteSections)\n",
    "# counter = 0\n",
    "# # for nonMute in nonMuteSections:\n",
    "# #     print(nonMute)\n",
    "# #     sf.write(f'temp/{counter}.wav',cut.audioData[nonMute[0]:nonMute[1]],cut.sampleRate)\n",
    "# #     counter = counter + 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/36458214/split-speech-audio-file-on-words-in-python **\n",
    "\n",
    "https://stackoverflow.com/questions/45526996/split-audio-files-using-silence-detection\n",
    "\n",
    "https://stackoverflow.com/questions/59102171/getting-timestamps-from-audio-using-python\n",
    "\n",
    "https://www.reddit.com/r/learnpython/comments/4st8sf/splitting_audio_file_into_segmentswords/\n",
    "\n",
    "https://www.geeksforgeeks.org/python-speech-recognition-on-large-audio-files/\n",
    "\n",
    "https://radiant-brushlands-42789.herokuapp.com/medium.com/better-programming/simple-audio-processing-in-python-with-pydub-c3a217dabf11\n",
    "\n",
    "https://www.thepythoncode.com/article/using-speech-recognition-to-convert-speech-to-text-python\n",
    "\n",
    "https://radiant-brushlands-42789.herokuapp.com/towardsdatascience.com/extracting-speech-from-video-using-python-f0ec7e312d38\n",
    "\n",
    "https://realpython.com/python-speech-recognition/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pydub import AudioSegment\n",
    "# from pydub.silence import split_on_silence\n",
    "# from pydub.silence import detect_nonsilent\n",
    "# def match_target_amplitude(sound, target_dBFS):\n",
    "#     change_in_dBFS = target_dBFS - sound.dBFS\n",
    "#     return sound.apply_gain(change_in_dBFS)\n",
    "# cut.ts_list_index[0]\n",
    "# # audio_chunks  = split_on_silence()\n",
    "# cut.audioData[cut.ts_list_index[1].start:cut.ts_list_index[1].end]\n",
    "# sound_file = AudioSegment.from_wav(\"example.wav\")\n",
    "# normalized_sound = match_target_amplitude(sound_file, -5.0)\n",
    "# nonsilent_data = detect_nonsilent(normalized_sound, min_silence_len=100, silence_thresh=-5, seek_step=1)\n",
    "# print(nonsilent_data)\n",
    "# nonsilent_index = []\n",
    "# print(\"start,Stop\")\n",
    "# for chunks in nonsilent_data:\n",
    "#      nonsilent_index.append([chunk/1000 for chunk in chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut.ts_list[0][0].get_seconds()\n",
    "cut.ts_list[-1][1].get_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('Model/mymodel/mymodel_78_18.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset()\n",
    "feature = ds.get_feature_by_file('Data/blindtest/for.wav')\n",
    "features = np.array(([feature]))\n",
    "print(features.shape)\n",
    "features.reshape(80,1)\n",
    "features.shape\n",
    "label = model.predict(features)\n",
    "print(label)\n",
    "print(np.round(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All below is the evaluation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Dataset:\n",
    "#     def __init__(self,feature,predict):\n",
    "#         self.feature = feature;\n",
    "#         self.predict = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Traindata:\n",
    "#     def __init__(self,fea,lab,head):\n",
    "#         self.features = fea\n",
    "#         self.labels = lab\n",
    "#         self.header = head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_confusion_matrixs(cm, classes,\n",
    "#                         normalize=False,\n",
    "#                         title='Confusion matrix',\n",
    "#                         cmap=plt.cm.Blues):\n",
    "#     \"\"\"\n",
    "#     This function prints and plots the confusion matrix.\n",
    "#     Normalization can be applied by setting `normalize=True`.\n",
    "#     \"\"\"\n",
    "#     plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     plt.title(title)\n",
    "#     plt.colorbar()\n",
    "#     tick_marks = np.arange(len(classes))\n",
    "#     plt.xticks(tick_marks, classes, rotation=45)\n",
    "#     plt.yticks(tick_marks, classes)\n",
    "\n",
    "#     if normalize:\n",
    "#         cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#         print(\"Normalized confusion matrix\")\n",
    "#     else:\n",
    "#         print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "#     thresh = cm.max() / 2.\n",
    "#     for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "#         plt.text(j, i, cm[i, j],\n",
    "#             horizontalalignment=\"center\",\n",
    "#             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.ylabel('True label')\n",
    "#     plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_data(link):\n",
    "#     dataset_name = link.split('/')[-1]\n",
    "#     file = tf.keras.utils.get_file(dataset_name,link,file_hash='sha256')\n",
    "#     CSV_HEADER = np.arange(80)\n",
    "#     CSV_HEADER = np.hstack((CSV_HEADER,['isStuttered','isSuccess']))\n",
    "#     label = ['isStuttered','isSuccess']\n",
    "#     dataframe = pd.read_csv(file, names=CSV_HEADER.tolist())\n",
    "#     isSuccess = dataframe.pop('isSuccess')\n",
    "#     labels = dataframe.pop('isStuttered')\n",
    "#     features = dataframe\n",
    "#     return (features,labels,CSV_HEADER)                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x,y,head = prepare_data('https://raw.githubusercontent.com/ming0520/training_data/main/20201126/20201126-cleanonly.csv')\n",
    "# cleanOnly = Traindata(x,y,head)\n",
    "# x,y,head = prepare_data('https://raw.githubusercontent.com/ming0520/training_data/main/20201221/20201221.csv')\n",
    "# IBM = Traindata(x,y,head)\n",
    "# x,y,head = prepare_data('https://raw.githubusercontent.com/ming0520/fyp2-data-20201126-fortrain/main/dataset_20201126.csv')\n",
    "# augmented = Traindata(x,y,head)\n",
    "# x,y,head = prepare_data('https://raw.githubusercontent.com/ming0520/training_data/main/test/test.csv')\n",
    "# test = Traindata(x,y,head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score, acc = model.evaluate(IBM.features, IBM.labels,batch_size=20)\n",
    "# print('Test score:', score)\n",
    "# print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputFeatures = test.features\n",
    "# inputLabels = test.labels\n",
    "# predictions = model.predict(x=inputFeatures, batch_size=10,verbose=0)\n",
    "# rounded_predictions = np.round(predictions)\n",
    "# yt= inputLabels.to_numpy()\n",
    "# yt = yt.reshape(yt.shape[0],1)\n",
    "# yTrue = np.round(yt)\n",
    "# # yTrue = yTrue.astype(dtype=np.float32)\n",
    "# cm = confusion_matrix(y_true=yTrue, y_pred=rounded_predictions)\n",
    "# cm_plot_labels = ['NoStuttered','isStuttered']\n",
    "# plot_confusion_matrix(cm=cm ,classes=cm_plot_labels, title='C Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = glob('Model/*.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Predict:\n",
    "#     def __init__(self,predict,ytrue,cm,title,score,acc):\n",
    "#         self.predict = predict\n",
    "#         self.ytrue = ytrue\n",
    "#         self.cm = cm\n",
    "#         self.title = title\n",
    "#         self.score = score\n",
    "#         self.acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predicts = []\n",
    "# fail_list = []\n",
    "# fig, axes = plt.subplots(nrows=len(models), ncols=1, figsize=(15,10))\n",
    "# for model_file in models:\n",
    "#     try:\n",
    "#         inputFeatures = test.features\n",
    "#         inputLabels = test.labels\n",
    "#         model = tf.keras.models.load_model(model_file)\n",
    "#         print('Model:',model_file)\n",
    "#         print('Test score:', score)\n",
    "#         print('Test accuracy:', acc)\n",
    "#         predictions = model.predict(x=inputFeatures, batch_size=10,verbose=0)\n",
    "#         rounded_predictions = np.round(predictions)\n",
    "#         yt= inputLabels.to_numpy()\n",
    "#         yt = yt.reshape(yt.shape[0],1)\n",
    "#         yTrue = np.round(yt)\n",
    "#         # yTrue = yTrue.astype(dtype=np.float32)\n",
    "#         cm = confusion_matrix(y_true=yTrue, y_pred=rounded_predictions)\n",
    "#         cm_plot_labels = ['NoStuttered','isStuttered']\n",
    "#         score, acc = model.evaluate(inputFeatures, inputLabels,batch_size=20)\n",
    "#         predicts.append(Predict(rounded_predictions,yTrue,cm,model_file,score,acc))\n",
    "# #         plot_confusion_matrix(cm=cm ,classes=cm_plot_labels, title=model_file)\n",
    "#     except:\n",
    "#         fail_list.append(model_file)\n",
    "# #     plot_confusion_matrix(cm=cm ,classes=cm_plot_labels, title='C Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pred in predicts:\n",
    "#     print('accuracy=>',pred.acc,'score=>',pred.score,'file=>',pred.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fail in fail_list:\n",
    "#     print(fail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows=len(models), ncols=1, figsize=(15,10))\n",
    "# cm_plot_labels = ['NoStuttered','isStuttered']\n",
    "# for pred, ax in zip(predicts, axes.flatten()):\n",
    "#     mod = tf.keras.models.load_model(pred.title)\n",
    "#     plot_confusion_matrix(cm=pred.cm ,classes=cm_plot_labels, title=pred.title)\n",
    "#     ax.title.set_text(pred.title)\n",
    "# plt.tight_layout()  \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicts.sort(key=lambda x: x.score, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newlist = sorted(predicts, key=lambda x: x.score, reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm_plot_labels = ['NoStuttered','isStuttered']\n",
    "# for pred in newlist:\n",
    "#     fig1 = plt.gcf()\n",
    "#     print('accuracy=>',pred.acc,'score=>',pred.score,'file=>',pred.title)\n",
    "#     ttl = pred.title + \" acc:\" + str(pred.acc) + \" sco:\" + str(pred.score)\n",
    "#     plot_confusion_matrix(cm=pred.cm ,classes=cm_plot_labels, title=ttl)\n",
    "#     plt.show()\n",
    "#     plt.draw()\n",
    "#     fig1.savefig(f'{pred.title}.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pythonGPU]",
   "language": "python",
   "name": "conda-env-pythonGPU-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
