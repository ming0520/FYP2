{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "prescribed-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timestamp:\n",
    "    def __init__(self,start = 0.0, end = 0.0, word='word', isInclude=False,feature=None, label=None):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.word = word\n",
    "        self.isInclude = isInclude\n",
    "        self.feature = feature\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sensitive-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "/*+----------------------------------------------------------------------\n",
    " ||\n",
    " ||  Class Timecode\n",
    " ||\n",
    " ||         Author:  Zhong Ming Tan\n",
    " ||\n",
    " ||        Purpose:  To make a robust timecode object and improve the existing python timecode class\n",
    " ||\n",
    " ||  Inherits From:  None\n",
    " ||\n",
    " ||     Interfaces:  None\n",
    " ||\n",
    " |+-----------------------------------------------------------------------\n",
    " ||\n",
    " ||      Constants:  None\n",
    " ||\n",
    " |+-----------------------------------------------------------------------\n",
    " ||\n",
    " ||   Constructors:  None\n",
    " ||\n",
    " ||  Class Methods:  set_fps(float), set_by_seconds(int), set_by_frames(int), set_by_timecode(str),\n",
    " ||                  ceil_frames(), floor_frames(),round_frame() ,get_fps():float, get_seconds():int,\n",
    " ||                  get_timecode():string, get_time():array, get_frames():int\n",
    " ||\n",
    " ||  Inst. Methods:  [List the names, arguments, and return types of all\n",
    " ||                   public instance methods.]\n",
    " ||\n",
    " ++-----------------------------------------------------------------------*/\n",
    "\"\"\"\n",
    "class Timecode:\n",
    "\n",
    "    def __init__ (self, fps=30,hours=0,minutes=0,seconds=0,frames=0):\n",
    "        self.framerate = float(fps)\n",
    "        self.hours = int(hours)\n",
    "        self.minutes = int(minutes)\n",
    "        self.seconds = int(seconds)\n",
    "        self.frames = int(frames)\n",
    "\n",
    "    def set_fps(self,fps):\n",
    "        self.framerate      =   float(fps)\n",
    "\n",
    "    def set_by_seconds(self, input):\n",
    "        self.set_by_frames(round(int(input)*self.framerate))\n",
    "    \n",
    "    def set_by_frames(self,frames):\n",
    "        total_seconds       =   frames/self.framerate\n",
    "        self.hours          =   int(total_seconds/3600)\n",
    "        self.minutes        =   int(total_seconds/60%60)\n",
    "        self.seconds        =   int(total_seconds%60)\n",
    "        self.frames         =   round((total_seconds-int(total_seconds))*self.framerate)\n",
    "\n",
    "    def set_by_timecode(self,timecode):\n",
    "        splittedTimecode    =   timecode.split(':')\n",
    "        self.hours          =   int(splittedTimecode[0])\n",
    "        self.minutes        =   int(splittedTimecode[1])\n",
    "        self.seconds        =   int(splittedTimecode[2])\n",
    "        self.frames         =   int(splittedTimecode[3])\n",
    "\n",
    "    def get_fps(self):\n",
    "        return self.framerate\n",
    "\n",
    "    def get_seconds(self):\n",
    "        total_seconds = ((self.hours*3600) + (self.minutes*60) + (self.seconds))\n",
    "        total_seconds = total_seconds + (self.frames/self.framerate)\n",
    "        return total_seconds\n",
    "\n",
    "    def get_time(self):\n",
    "        return [self.hours,self.minutes,self.seconds,self.frames]\n",
    "    \n",
    "    def get_timecode(self):\n",
    "        return '{h:02d}:{m:02d}:{s:02d}:{f:02d}'.format(h=self.hours,m=self.minutes,s=self.seconds,f=self.frames)\n",
    "    \n",
    "    def get_timecode_ffmpeg(self):\n",
    "        return '{h:02d}:{m:02d}:{s:f}' \\\n",
    "        .format(h=self.hours,\n",
    "                m=self.minutes,\n",
    "                s=( float( self.seconds + (self.frames/self.framerate) ) )\n",
    "               )        \n",
    "    \n",
    "    def get_frames(self):\n",
    "        total_seconds = int((self.hours*3600) + (self.minutes*60) + (self.seconds))\n",
    "        total_frames = int((total_seconds * self.framerate) + self.frames)\n",
    "        return total_frames\n",
    "    \n",
    "    def ceil_frames(self):\n",
    "        if self.frames > 0:\n",
    "            ceil_seconds = self.get_seconds() + 1\n",
    "            self.set_by_seconds(ceil_seconds)\n",
    "\n",
    "    def floor_frames(self):\n",
    "        if self.frames > 0:\n",
    "            self.frames = 0\n",
    "    \n",
    "    def round_frames(self):\n",
    "        threshold = self.framerate / 2\n",
    "        if self.frames > threshold:\n",
    "            self.ceil_seconds()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "little-drinking",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a17f1f0e816c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# audio related\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "# Start Auto Edit Library\n",
    "\n",
    "# os system processing library\n",
    "import shutil\n",
    "import json\n",
    "from glob import glob\n",
    "from shutil import move, rmtree, copyfile\n",
    "\n",
    "# mathematic operation\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# audio related\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# display libary\n",
    "import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "\n",
    "class FeatureExtraction:\n",
    "    def __init__(self, n_mels=128):\n",
    "        self.n_mels = n_mels\n",
    "        self.y = None\n",
    "        self.sr = 11025\n",
    "        self.S = None\n",
    "        self.log_S = None\n",
    "        self.mfcc = None\n",
    "        self.delta_mfcc = None\n",
    "        self.delta2_mfcc = None\n",
    "        self.M = None\n",
    "        self.rmse = None\n",
    "        self.foldername = None\n",
    "        self.filename=None\n",
    "    \n",
    "    def loadFile(self, foldernname):\n",
    "        self.foldernname=foldernname\n",
    "        self.y, self.sr = librosa.load(foldernname)\n",
    "    \n",
    "    def load_y_sr(self, y, sr):\n",
    "        self.y = y\n",
    "        self.sr = sr\n",
    "    \n",
    "    def melspectrogram(self):\n",
    "        self.S = librosa.feature.melspectrogram(self.y, sr=self.sr, n_mels=self.n_mels)\n",
    "        self.log_S = librosa.amplitude_to_db(self.S)\n",
    "    \n",
    "    def plotmelspectrogram(self, save=True):\n",
    "        fig = plt.figure(figsize=(12, 4))\n",
    "        librosa.display.specshow(self.log_S, sr=self.sr, x_axis='time', y_axis='mel')\n",
    "        plt.title(f'mel Power Spectrogram ({self.filename})')\n",
    "        plt.colorbar(format='%+02.0f dB')\n",
    "        plt.tight_layout()\n",
    "        if not os.path.exists('mel'):\n",
    "            os.mkdir('mel')\n",
    "        if save:\n",
    "            fig.savefig(f'./mel/{self.filename}-mel.png', dpi=fig.dpi)\n",
    "            print(f'Saved to ./mel/{self.filename}-mel.png')\n",
    "            plt.close('all')\n",
    "\n",
    "    def extractmfcc(self, n_mfcc=13):\n",
    "        self.mfcc = librosa.feature.mfcc(S=self.log_S, n_mfcc=n_mfcc)\n",
    "        self.delta_mfcc = librosa.feature.delta(self.mfcc,mode='nearest')\n",
    "        self.delta2_mfcc = librosa.feature.delta(self.mfcc, order=2,mode='nearest')\n",
    "        self.M = np.vstack([self.mfcc, self.delta_mfcc, self.delta2_mfcc])\n",
    "    \n",
    "    def plotmfcc(self,save=False):\n",
    "        fig = plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(3, 1, 1)\n",
    "        librosa.display.specshow(self.mfcc)\n",
    "        plt.title(f'mel Power Spectrogram ({self.filename})')\n",
    "        plt.ylabel('MFCC')\n",
    "        plt.colorbar()\n",
    "        \n",
    "        plt.subplot(3, 1, 2)\n",
    "        librosa.display.specshow(self.delta_mfcc)\n",
    "        plt.title(f'mel Power Spectrogram ({self.filename})')\n",
    "        plt.ylabel('MFCC-$\\Delta$')\n",
    "        plt.colorbar()\n",
    "        \n",
    "        plt.subplot(3, 1, 3)\n",
    "        librosa.display.specshow(self.delta2_mfcc, sr=self.sr, x_axis='time')\n",
    "        plt.title(f'mel Power Spectrogram ({self.filename})')\n",
    "        plt.ylabel('MFCC-$\\Delta^2$')\n",
    "        plt.colorbar()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        if not os.path.exists('mfcc'):\n",
    "            os.mkdir('mfcc')\n",
    "        if save:\n",
    "            fig.savefig(f'./mfcc/{self.filename}-mfcc.png', dpi=fig.dpi)\n",
    "            print(f'Saved to ./mfcc/{self.filename}-mfcc.png')\n",
    "            plt.close('all')\n",
    "\n",
    "    def extractrmse(self):\n",
    "        self.rmse = librosa.feature.rms(y=self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Auto Edit Library\n",
    "\n",
    "# os system processing library\n",
    "import shutil\n",
    "import json\n",
    "from glob import glob\n",
    "from shutil import move, rmtree, copyfile\n",
    "\n",
    "# mathematic operation\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# audio related\n",
    "import librosa\n",
    "\n",
    "# display libary\n",
    "import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "# developed library\n",
    "import importlib\n",
    "\n",
    "import module.FeatureExtraction\n",
    "\n",
    "importlib.reload(module.FeatureExtraction)\n",
    "\n",
    "from module.FeatureExtraction import FeatureExtraction\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self,):\n",
    "        self.X = np.empty(shape=(0,80))\n",
    "        self.Y = np.empty(shape=(0,2))\n",
    "        self.DATASET = None\n",
    "        self.PATH_ARRAY = []\n",
    "        self.failed_file = []\n",
    "        self.unexpected_label = []\n",
    "        self.processed_counter = 0\n",
    "        print(\"Object created!\")\n",
    "\n",
    "    def create_dataset(self,dataset_path,output_path):\n",
    "        self.DATASET_PATH = dataset_path\n",
    "        self.OUTPUT_PATH = output_path\n",
    "        self.__process_dataset()\n",
    "        self.__write_to_file()\n",
    "        \n",
    "    def get_feature_by_audio(self,y,sr):\n",
    "          #exctract mfcc\n",
    "        try:\n",
    "            features = FeatureExtraction()\n",
    "            features.load_y_sr(y,sr)\n",
    "            features.melspectrogram()\n",
    "            features.extractmfcc()\n",
    "            features.extractrmse()\n",
    "        except ValueError:\n",
    "            self.failed_file.append(ValueError)\n",
    "            print(ValueError)\n",
    "\n",
    "        feature_vector = []\n",
    "\n",
    "        for feature in features.mfcc:\n",
    "            feature_vector.append(np.mean(feature))\n",
    "            feature_vector.append(np.var(feature))\n",
    "\n",
    "        for feature in features.delta_mfcc:\n",
    "            feature_vector.append(np.mean(feature))\n",
    "            feature_vector.append(np.var(feature))\n",
    "\n",
    "        for feature in features.delta2_mfcc:\n",
    "            feature_vector.append(np.mean(feature))\n",
    "            feature_vector.append(np.var(feature))\n",
    "\n",
    "        feature_vector.append(np.mean(features.rmse))\n",
    "        feature_vector.append(np.var(features.rmse))\n",
    "\n",
    "        return feature_vector\n",
    "        \n",
    "    def get_feature_by_file(self,audio):\n",
    "        print(\"Extacting feature:\", audio)\n",
    "        try:\n",
    "            features = FeatureExtraction()\n",
    "            features.loadFile(audio)\n",
    "            features.melspectrogram()\n",
    "            features.extractmfcc()\n",
    "            features.extractrmse()\n",
    "        except ValueError:\n",
    "            self.failed_file.apppend(file_path)\n",
    "\n",
    "        feature_vector = []\n",
    "\n",
    "        for feature in features.mfcc:\n",
    "            feature_vector.append(np.mean(feature))\n",
    "            feature_vector.append(np.var(feature))\n",
    "\n",
    "        for feature in features.delta_mfcc:\n",
    "            feature_vector.append(np.mean(feature))\n",
    "            feature_vector.append(np.var(feature))\n",
    "\n",
    "        for feature in features.delta2_mfcc:\n",
    "            feature_vector.append(np.mean(feature))\n",
    "            feature_vector.append(np.var(feature))\n",
    "\n",
    "        feature_vector.append(np.mean(features.rmse))\n",
    "        feature_vector.append(np.var(features.rmse))\n",
    "\n",
    "        return feature_vector\n",
    "        \n",
    "    def __process_dataset(self):\n",
    "        starttime = time.time()\n",
    "        for i , (dirpath, dirnames, filenames) in enumerate(os.walk(self.DATASET_PATH)):\n",
    "              if dirpath is not self.DATASET_PATH:\n",
    "                label = dirpath.split(\"/\")[-1]\n",
    "                # print(label)\n",
    "                print(\"Processing:\", label)\n",
    "                for file in filenames:\n",
    "                  #load audio\n",
    "                  file_path = os.path.join(dirpath,file)\n",
    "\n",
    "                  # print(file_path)\n",
    "\n",
    "                  #exctract mfcc\n",
    "                try:\n",
    "                    features = FeatureExtraction()\n",
    "                    features.loadFile(file_path)\n",
    "                    features.melspectrogram()\n",
    "                    features.extractmfcc()\n",
    "                    features.extractrmse()\n",
    "                except ValueError:\n",
    "                    self.failed_file.apppend(file_path)\n",
    "\n",
    "                feature_vector = []\n",
    "\n",
    "                for feature in features.mfcc:\n",
    "                    feature_vector.append(np.mean(feature))\n",
    "                    feature_vector.append(np.var(feature))\n",
    "\n",
    "                for feature in features.delta_mfcc:\n",
    "                    feature_vector.append(np.mean(feature))\n",
    "                    feature_vector.append(np.var(feature))\n",
    "\n",
    "                for feature in features.delta2_mfcc:\n",
    "                    feature_vector.append(np.mean(feature))\n",
    "                    feature_vector.append(np.var(feature))\n",
    "\n",
    "                feature_vector.append(np.mean(features.rmse))\n",
    "                feature_vector.append(np.var(features.rmse))\n",
    "\n",
    "                self.X = np.vstack((self.X,[feature_vector]))\n",
    "                if label == 'success':\n",
    "                    self.Y = np.vstack((self.Y,[0,1]))\n",
    "                    self.processed_counter += 1\n",
    "                    print(\"Done \", self.processed_counter, file_path,' label=',label)\n",
    "                elif label == 'stuttered':\n",
    "                    self.Y = np.vstack((self.Y,[1,0]))\n",
    "                    self.processed_counter += 1\n",
    "                    print(\"Done \", self.processed_counter, file_path,' label=',label)\n",
    "                else:\n",
    "                    self.unexpected_label.append(file_path)\n",
    "                    print(\"Fail \", self.processed_counter, file_path,' label=',label)\n",
    "\n",
    "        for fail in self.unexpected_label:\n",
    "            print(\"unexpected_label \", file_path, \" !\")\n",
    "\n",
    "        for fail in self.failed_file:\n",
    "            print(\"fail \", file_path, \" !\")\n",
    "\n",
    "        # print(\"finished all!\")\n",
    "        print('Time taken = {} seconds'.format(time.time() - starttime))    \n",
    "        self.DATASET = np.hstack((self.X,self.Y))\n",
    "\n",
    "    def load_dataset(self,dataset_path):\n",
    "        self.DATASET_PATH = dataset_path\n",
    "\n",
    "        if os.path.exists(self.DATASET_PATH):\n",
    "            print(\"Dataset exist!\")\n",
    "        else:\n",
    "            print('Not found ',self.DATASET_PATH)\n",
    "            return\n",
    "\n",
    "        self.FILE_NAME, self.FILE_TYPE = os.path.splitext(self.DATASET_PATH)\n",
    "\n",
    "        print(\"Loading \", self.DATASET_PATH)\n",
    "        if self.FILE_TYPE == '.csv':\n",
    "            print('Detect as .csv file')\n",
    "            self.DATA = np.genfromtxt(self.DATASET_PATH, delimiter=',')\n",
    "        elif self.FILE_TYPE == '.gz':\n",
    "            print('Detect as .gz file')\n",
    "            self.DATA = np.loadtxt(self.DATASET_PATH)\n",
    "        else:\n",
    "            print(\"Only support .gz and .csv file\")\n",
    "            return False\n",
    "\n",
    "        self.X = self.DATA[:, 0:80]\n",
    "        self.Y = self.DATA[:, 80:]\n",
    "\n",
    "    def convert_to_csv(self,output_file):\n",
    "        if os.path.exists(output_file):\n",
    "            os.remove(output_file)\n",
    "        np.savetxt(output_file,self.DATA, delimiter=',')\n",
    "        print('Converted to',output_file)      \n",
    "\n",
    "    def __write_to_file(self):\n",
    "        if os.path.exists(self.OUTPUT_PATH):\n",
    "            os.remove(self.OUTPUT_PATH)\n",
    "\n",
    "        np.savetxt(self.OUTPUT_PATH, self.DATASET)\n",
    "        print('Saved to',self.OUTPUT_PATH)  \n",
    "\n",
    "    def get_x(self):\n",
    "        return self.X\n",
    "\n",
    "    def get_y(self):\n",
    "        return self.Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import vosk\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class VoskProcess:\n",
    "    def __init__(self,vosk_path='vosk-model-small-en-us-0.15'):\n",
    "        print('Loading vosk...')\n",
    "        vosk.SetLogLevel(-1)\n",
    "        self.VOSK_PATH = vosk_path\n",
    "        self.vosk_model = vosk.Model(self.VOSK_PATH)\n",
    "        print('Loaded vosk!')\n",
    "\n",
    "    def extract_words(self,res):\n",
    "        jres = json.loads(res)\n",
    "        if not 'result' in jres:\n",
    "            return []\n",
    "        words = jres['result']\n",
    "        return words\n",
    "\n",
    "    def transcribe_words(self,recognizer, bytes):\n",
    "        results = []\n",
    "\n",
    "        chunk_size = 4000\n",
    "        for chunk_no in range(math.ceil(len(bytes)/chunk_size)):\n",
    "            start = chunk_no*chunk_size\n",
    "            end = min(len(bytes), (chunk_no+1)*chunk_size)\n",
    "            data = bytes[start:end]\n",
    "\n",
    "            if recognizer.AcceptWaveform(data):\n",
    "                words = self.extract_words(recognizer.Result())\n",
    "                results += words\n",
    "        results += self.extract_words(recognizer.FinalResult())\n",
    "\n",
    "        return results                \n",
    "\n",
    "    def transcribe(self,audioData):\n",
    "        print('Creating recognizer ...')\n",
    "        self.recognizer = vosk.KaldiRecognizer(self.vosk_model, 16000)\n",
    "        print('Created recognizer')\n",
    "        self.audioData = audioData\n",
    "        int16 = np.int16(self.audioData * 32768).tobytes()\n",
    "        # vosk_path = self.VOSK_PATH\n",
    "        # vosk_model = vosk.Model(vosk_path) \n",
    "        print('Transcribing...')\n",
    "        res = self.transcribe_words(self.recognizer, int16)\n",
    "        df = pd.DataFrame.from_records(res)\n",
    "        df = df.sort_values('start')\n",
    "        print('Completed transcribe')\n",
    "        self.df = df\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Auto Edit Library\n",
    "\n",
    "# os system processing library\n",
    "import subprocess\n",
    "import shutil\n",
    "import json\n",
    "from glob import glob\n",
    "from shutil import move, rmtree, copyfile\n",
    "import os\n",
    "\n",
    "# mathematic operation\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# audio related\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import vosk\n",
    "\n",
    "# display libary\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# machine learning libary\n",
    "import tensorflow as tf\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "# developed library\n",
    "import importlib\n",
    "\n",
    "import module.Timecode\n",
    "import module.FeatureExtraction\n",
    "import module.Dataset\n",
    "import module.Timestamp\n",
    "\n",
    "importlib.reload(module.Timecode)\n",
    "importlib.reload(module.FeatureExtraction)\n",
    "importlib.reload(module.Dataset)\n",
    "importlib.reload(module.Timestamp)\n",
    "\n",
    "from module.Timecode import Timecode\n",
    "from module.FeatureExtraction import FeatureExtraction\n",
    "from module.Dataset import Dataset\n",
    "from module.Timestamp import Timestamp\n",
    "\n",
    "\n",
    "class AutoEdit:\n",
    "    def __init__(self, file=None, ba='160000', ac='1', ar='16000',output_format='.wav', fps = 30.0, \n",
    "                 st = 0.04, fm = 4, lt = 2.00, verbose = False, isRender = True,\n",
    "                 log=False, mono = True, \n",
    "                 model='Model/mymodel_78_18.h5'):\n",
    "        #parameter for ffmpeg to convert the file\n",
    "        self.MODEL_PATH = model\n",
    "        self.INPUT_FILE = file\n",
    "        if(file != None):\n",
    "            self.FILENAME = file.split('.')[0]\n",
    "        else:\n",
    "            self.FILENAME = None\n",
    "        self.AUDIO_OUTPUT_FORMAT = output_format\n",
    "        if(file != None):\n",
    "            self.AUDIO_OUTPUT = f'{self.FILENAME}{self.AUDIO_OUTPUT_FORMAT}'\n",
    "        else:\n",
    "            self.AUDIO_OUTPUT = None\n",
    "        \n",
    "        self.BITRATE_AUDIO = ba\n",
    "        self.AUDIO_CHANEL = ac\n",
    "        self.AUDIO_RATE = ar\n",
    "        self.FRAME_RATE = fps\n",
    "        \n",
    "        self.FRAME_MARGIN = fm\n",
    "        self.SILENT_THRESHOLD = st\n",
    "        self.LOUDNESS_THRESHOLD = lt\n",
    "        \n",
    "        self.VERBOSE = verbose\n",
    "        \n",
    "        self.audioData = None\n",
    "        self.sampleRate = None\n",
    "        \n",
    "        self.audioSampleCount = None\n",
    "        self.maxAudioVolume = None\n",
    "        self.samplesPerFrame = None\n",
    "        self.audioFrameCount = None\n",
    "        self.hasLoudAudio = None\n",
    "        \n",
    "        self.chunks = None\n",
    "        self.shouldIncludeFrame = None\n",
    "        self.timecodeList = None\n",
    "        self.chunks_path = 'chunks.txt'\n",
    "        self.log = log\n",
    "        self.isMono = mono\n",
    "        self.VOSK_PATH = 'vosk-model-small-en-us-0.15'\n",
    "        self.isRender = isRender\n",
    "        # self.VOSK_PATH = 'vosk-model-en-us-aspire-0.2'\n",
    "            \n",
    "    def extract_audio(self):\n",
    "        if self.INPUT_FILE == None:\n",
    "            print(\"No input file!\")\n",
    "            \n",
    "        cmd = ['ffmpeg', '-y' ,'-i',self.INPUT_FILE,'-acodec','pcm_s16le' ,'-b:a', self.BITRATE_AUDIO, '-ac', self.AUDIO_CHANEL, \n",
    "               '-ar', self.AUDIO_RATE, '-vn', f'{self.AUDIO_OUTPUT}']\n",
    "        #ffmpeg -i \"%%a\" -acodec pcm_s16le -ac 1 -ar 16000 -af lowpass=3000,highpass=200 \"converted\\%%~na.wav\n",
    "        # ffmpeg -y -i SBLQ.mp4 -acodec pcm_s16le -b:a 16k -ac 1 -ar 16000 -vn output.wav\n",
    "\n",
    "        # ffmpeg -y -i SBLQ.mp4 -acodec libmp3lame -b:a 16k -ac 1 -ar 16000 -vn output.mp3\n",
    "        if(not self.VERBOSE):\n",
    "            cmd.extend(['-nostats', '-loglevel', '0'])\n",
    "        subprocess.call(cmd)\n",
    "        \n",
    "    def get_max_volume(self,s):\n",
    "        maxv = float(np.max(s))\n",
    "        minv = float(np.min(s))\n",
    "        return max(maxv, -minv)\n",
    "\n",
    "    def load_audio(self):\n",
    "        # self.sampleRate,self.audioData = wavfile.read(f'{self.AUDIO_OUTPUT}')\n",
    "        self.audioData,self.sampleRate = librosa.load(f'{self.AUDIO_OUTPUT}',\n",
    "        mono = self.isMono,sr=self.sampleRate)\n",
    "\n",
    "        self.audioSampleCount = self.audioData.shape[0]\n",
    "        self.maxAudioVolume = self.get_max_volume(self.audioData)\n",
    "        self.samplesPerFrame = self.sampleRate / self.FRAME_RATE\n",
    "        self.audioFrameCount = int(math.ceil(self.audioSampleCount / self.samplesPerFrame))\n",
    "    \n",
    "    def get_shape(self):\n",
    "        return self.audioData.shape\n",
    "    \n",
    "    def calc_has_loud_audio(self):\n",
    "        self.hasLoudAudio = np.zeros((self.audioFrameCount))\n",
    "        \n",
    "        for i in range(self.audioFrameCount):\n",
    "            start = int(i * self.samplesPerFrame)\n",
    "            end = min( int( (i+1) * self.samplesPerFrame ), self.audioSampleCount)\n",
    "            audiochunks = self.audioData[start:end]\n",
    "            maxchunksVolume = self.get_max_volume(audiochunks) / self.maxAudioVolume\n",
    "            \n",
    "            if(maxchunksVolume >= self.LOUDNESS_THRESHOLD):\n",
    "                self.hasLoudAudio[i] = 2\n",
    "            elif(maxchunksVolume >= self.SILENT_THRESHOLD):\n",
    "                self.hasLoudAudio[i] = 1\n",
    "    \n",
    "    def calc_should_include_frame(self):\n",
    "        self.shouldIncludeFrame = np.zeros((self.audioFrameCount))\n",
    "        self.chunks = [[0,0,0]]\n",
    "        \n",
    "        for i in range(self.audioFrameCount):\n",
    "            start = int(max(0, i-self.FRAME_MARGIN))\n",
    "            end = int(min(self.audioFrameCount, i+1+self.FRAME_MARGIN))\n",
    "            self.shouldIncludeFrame[i] = min(1,np.max(self.hasLoudAudio[start:end]))\n",
    "\n",
    "            if(i >= 1 and self.shouldIncludeFrame[i] != self.shouldIncludeFrame[i-1]):\n",
    "                self.chunks.append([self.chunks[-1][1], i, self.shouldIncludeFrame[i-1]])\n",
    "        self.chunks.append([self.chunks[-1][1], self.audioFrameCount, self.shouldIncludeFrame[i-1]])\n",
    "        self.chunks = self.chunks[1:]\n",
    "        \n",
    "    def calc_timecode(self):\n",
    "        self.timecodeList = []\n",
    "        \n",
    "        for chunk in self.chunks:\n",
    "            startTime = Timecode(fps=self.FRAME_RATE)\n",
    "            endTime = Timecode(fps=self.FRAME_RATE)\n",
    "            \n",
    "            startTime.set_by_frames(chunk[0])\n",
    "            endTime.set_by_frames(chunk[1])\n",
    "            isInclude = chunk[2]\n",
    "            self.timecodeList.append([startTime,endTime,isInclude])\n",
    "            \n",
    "    def execute(self):\n",
    "        print('Executing command...')\n",
    "        command = 'bash ./run.sh'\n",
    "        if os.path.exists('run.sh'):\n",
    "            # if self.log:\n",
    "            #      command += ' > log.txt'    \n",
    "            output = subprocess.call(command,shell=True)\n",
    "        if self.VERBOSE:\n",
    "            print(\"Complex filter command success\") if output == 0 else print(\"Complex filter command failed!\")\n",
    "      \n",
    "            \n",
    "            \n",
    "    def write_to_bat(self,command):\n",
    "        if(self.isRender == False):\n",
    "            return\n",
    "        if os.path.exists('run.sh'):\n",
    "            os.remove(f'run.sh')\n",
    "        file1 = open(\"run.sh\",\"w\")\n",
    "        file1.write(command)\n",
    "        file1.close()\n",
    "        filename = 'run.sh'\n",
    "        # if self.log:\n",
    "        #     filename += ' > log.txt'\n",
    "        return filename\n",
    "    \n",
    "    def produce_concat_file(self):\n",
    "        if os.path.exists(self.chunks_path):\n",
    "            os.remove(self.chunks_path)\n",
    "            \n",
    "        with open(self.chunks_path, 'w') as f:\n",
    "            for index in range(len(self.timecodeList)):\n",
    "                isInclude = float(self.timecodeList[index][2])\n",
    "                if isInclude < 1:\n",
    "                    continue;\n",
    "                # startTime = self.timecodeList[index][0].get_timecode_ffmpeg()\n",
    "                # endTime = self.timecodeList[index][1].get_timecode_ffmpeg()\n",
    "                startTime = self.timecodeList[index][0].get_seconds()\n",
    "                endTime = self.timecodeList[index][1].get_seconds()\n",
    "                f.write(f'file {self.INPUT_FILE}\\ninpoint {startTime}\\noutpoint {endTime}\\n')\n",
    "    \n",
    "    def concat_way(self):\n",
    "        concat = ['ffmpeg','-y','-f','concat','-safe','0','-i', f'{self.chunks_path}',\n",
    "                 '-async','1','-framerate', f'{self.FRAME_RATE}','-b:a', f'{self.BITRATE_AUDIO}',\n",
    "                 '-c:v', 'copy', '-ar', f'{self.AUDIO_RATE}', '-ac', f'{self.AUDIO_CHANEL}',\n",
    "                 '-c:a','aac','-movflags','+faststart',f'{self.FILENAME}_CONCATED.mp4']\n",
    "        subprocess.call(concat)\n",
    "        \n",
    "    def select_filter(self):\n",
    "        \n",
    "        between = []\n",
    "        counter = 0\n",
    "        for i in self.timecodeList:\n",
    "            if i[2] > 0:\n",
    "#                 print(f'{self.INPUT_FILE},{i[0].get_seconds()},{i[1].get_seconds()}')\n",
    "                between.append(f'between(t,{i[0].get_seconds()},{i[1].get_seconds()})') \n",
    "        \n",
    "        betweens = '+'.join(between)\n",
    "        slt = '\\\"select=\\'' + betweens + '\\'' + ',setpts=N/FRAME_RATE/TB\\\"'\n",
    "        aslt = '\\\"aselect=\\'' + betweens + '\\'' + ',asetpts=N/SR/TB\\\"'\n",
    "        \n",
    "        sltFilter = ['ffmpeg','-y','-i',f'{self.INPUT_FILE}', '-vf', \n",
    "                     f'{slt}','-af', f'{aslt}',\n",
    "                     f'{self.FILENAME}_FILTERED.mp4']\n",
    "        \n",
    "        total_string = ' '.join(sltFilter)\n",
    "#         if self.log:\n",
    "#             total_string += \" > log.txt 2>&1\";\n",
    "        bat_path = self.write_to_bat(total_string)\n",
    "        # output = subprocess.call(bat_path,shell=True)\n",
    "        self.execute()\n",
    "        if self.VERBOSE:\n",
    "            print(\"Select filter command success\") if output == 0 else print(\"Select filter command failed!\")\n",
    "            \n",
    "    def remove_silence(self):\n",
    "        trim = []\n",
    "        duration_list = []\n",
    "        number_of_segment = 0\n",
    "        prev = 0\n",
    "        current = 0\n",
    "\n",
    "        # with out xfade\n",
    "        for i in self.timecodeList:\n",
    "            if i[2] > 0:\n",
    "                duration_list.append(i[0].get_seconds()-i[1].get_seconds())\n",
    "                trim.append(\n",
    "                    f'[0:v]trim=start={i[0].get_seconds()}:end={i[1].get_seconds()},setpts=PTS-STARTPTS[v{number_of_segment}]')\n",
    "                trim.append(\n",
    "                    f'[0:a]atrim=start={i[0].get_seconds()}:end={i[1].get_seconds()},asetpts=PTS-STARTPTS[a{number_of_segment}]')\n",
    "                number_of_segment += 1\n",
    "\n",
    "                \n",
    "        filter = ';'.join(trim)\n",
    "        filter = filter + \";\"\n",
    "\n",
    "        # Normal cut feature\n",
    "        for i in range(number_of_segment):\n",
    "            filter += f' [v{i}] [a{i}]'\n",
    "\n",
    "        # Start to generate ending of command\n",
    "        filter += f'concat=n={number_of_segment}:v=1:a=1 [out]'\n",
    "        filter = '\"' + filter + '\"'\n",
    "        filter = f'ffmpeg -y -i {self.INPUT_FILE} -filter_complex ' + filter\n",
    "        filter = filter + f' -map \"[out]\" {self.FILENAME}_SILENCE.mp4'\n",
    "            \n",
    "        bat_path = self.write_to_bat(filter)     \n",
    "    \n",
    "\n",
    "    def fliter_complex(self):\n",
    "        trim = []\n",
    "        duration_list = []\n",
    "        number_of_segment = 0\n",
    "        prev = 0\n",
    "        current = 0\n",
    "\n",
    "        # with out xfade\n",
    "        for i in self.timecodeList:\n",
    "            if i[2] > 0:\n",
    "                duration_list.append(i[0].get_seconds()-i[1].get_seconds())\n",
    "                trim.append(\n",
    "                    f'[0:v]trim=start={i[0].get_seconds()}:end={i[1].get_seconds()},setpts=PTS-STARTPTS[v{number_of_segment}]')\n",
    "                trim.append(\n",
    "                    f'[0:a]atrim=start={i[0].get_seconds()}:end={i[1].get_seconds()},asetpts=PTS-STARTPTS[a{number_of_segment}]')\n",
    "                number_of_segment += 1\n",
    "                \n",
    "        filter = ';'.join(trim)\n",
    "        filter = filter + \";\"\n",
    "\n",
    "        # Normal cut feature\n",
    "        for i in range(number_of_segment):\n",
    "            filter += f' [v{i}] [a{i}]'\n",
    "\n",
    "        # Start to generate ending of command\n",
    "        filter += f'concat=n={number_of_segment}:v=1:a=1 [out]'\n",
    "        filter = '\"' + filter + '\"'\n",
    "        filter = f'ffmpeg -y -i {self.INPUT_FILE} -filter_complex ' + filter\n",
    "        filter = filter + f' -map \"[out]\" {self.FILENAME}_COMPLEX.mp4'\n",
    "\n",
    "        bat_path = self.write_to_bat(filter)\n",
    "        self.execute()\n",
    "        output = 1\n",
    "        if self.VERBOSE:\n",
    "            print(\"Complex filter command success\") if output == 0 else print(\"Complex filter command failed!\")\n",
    "    \n",
    "    \n",
    "    def post_process(self):\n",
    "        if os.path.exists(f'{self.chunks_path}'):\n",
    "            os.remove(f'{self.chunks_path}')\n",
    "            if self.VERBOSE:\n",
    "                print(f\"Removed {self.chunks_path}\")\n",
    "                \n",
    "        if os.path.exists(f'{self.AUDIO_OUTPUT}'):\n",
    "            os.remove(f'{self.AUDIO_OUTPUT}')\n",
    "            if self.VERBOSE:\n",
    "                print(f\"Removed {self.AUDIO_OUTPUT}\")\n",
    "        return f'{self.FILENAME}_COMPLEX.mp4'\n",
    "       \n",
    "        \n",
    "    def export_complex(self):\n",
    "        self.pbar = tqdm(total=7)\n",
    "        print(\"Start processing...\")\n",
    "        self.extract_audio()\n",
    "        self.update_mypbar()\n",
    "        self.load_audio()\n",
    "        self.update_mypbar()\n",
    "        self.calc_has_loud_audio()\n",
    "        self.update_mypbar()\n",
    "        self.calc_should_include_frame()\n",
    "        self.update_mypbar()\n",
    "        self.calc_timecode()\n",
    "        self.update_mypbar()\n",
    "        \n",
    "        print(f'Exporting {self.FILENAME}_COMPLEX.mp4 ...')\n",
    "        self.fliter_complex()\n",
    "        self.update_mypbar()\n",
    "        print(f'Exported {self.FILENAME}_COMPLEX.mp4 successfully!')\n",
    "        \n",
    "        self.post_process()\n",
    "        self.update_mypbar()\n",
    "        self.pbar.close()\n",
    "        \n",
    "    def export_fast(self):\n",
    "        try:\n",
    "            self.extract_audio()\n",
    "            self.load_audio()\n",
    "            self.calc_has_loud_audio()\n",
    "            self.calc_should_include_frame()\n",
    "            self.calc_timecode()\n",
    "            self.produce_concat_file()\n",
    "            self.concat_way()\n",
    "            self.post_process()\n",
    "            if(self.VERBOSE):\n",
    "                print(f'Exported {self.FILENAME}_CONCATED.mp4 successfully!')\n",
    "        except:\n",
    "            print('Failed to export fast!')\n",
    "\n",
    "        return f'{self.FILENAME}_CONCATED.mp4'\n",
    "            \n",
    "    def update_mypbar(self):\n",
    "        self.pbar.update(1)\n",
    "        time.sleep(0.01)\n",
    "        self.pbar.refresh()\n",
    "            \n",
    "    def export_good(self):\n",
    "        self.pbar = tqdm(total=7)\n",
    "        try:\n",
    "            print(\"Start processing...\")\n",
    "            self.extract_audio()\n",
    "            self.update_mypbar()\n",
    "\n",
    "            self.load_audio()\n",
    "            self.update_mypbar()\n",
    "\n",
    "            self.calc_has_loud_audio()\n",
    "            self.update_mypbar()\n",
    "            self.calc_should_include_frame()\n",
    "            self.update_mypbar()\n",
    "            self.calc_timecode()\n",
    "            self.update_mypbar()\n",
    "            \n",
    "            print(f'Exporting {self.FILENAME}_FILTERED.mp4 ...')\n",
    "            self.select_filter()\n",
    "            self.update_mypbar()\n",
    "            print(f'Exported {self.FILENAME}_FILTERED.mp4 successfully!')\n",
    "  \n",
    "            self.post_process()\n",
    "            self.update_mypbar()\n",
    "            self.pbar.close()\n",
    "        except:\n",
    "            print(f'Failed to export {self.FILENAME}_FILTERED.mp4 !')\n",
    "        return f'{self.FILENAME}_FILTERED.mp4'\n",
    "            \n",
    "    def extract_words(self,res):\n",
    "        jres = json.loads(res)\n",
    "        if not 'result' in jres:\n",
    "            return []\n",
    "        words = jres['result']\n",
    "        return words\n",
    "\n",
    "    def transcribe_words(self,recognizer, bytes):\n",
    "        results = []\n",
    "\n",
    "        chunk_size = 4000\n",
    "        for chunk_no in range(math.ceil(len(bytes)/chunk_size)):\n",
    "            start = chunk_no*chunk_size\n",
    "            end = min(len(bytes), (chunk_no+1)*chunk_size)\n",
    "            data = bytes[start:end]\n",
    "\n",
    "            if recognizer.AcceptWaveform(data):\n",
    "                words = self.extract_words(recognizer.Result())\n",
    "                results += words\n",
    "        results += self.extract_words(recognizer.FinalResult())\n",
    "\n",
    "        return results                \n",
    "\n",
    "    def vosk_process(self):\n",
    "        print('Loading vosk...')\n",
    "        vosk.SetLogLevel(-1)\n",
    "        int16 = np.int16(self.audioData * 32768).tobytes()\n",
    "        vosk_path = self.VOSK_PATH\n",
    "        vosk_model = vosk.Model(vosk_path)\n",
    "        recognizer = vosk.KaldiRecognizer(vosk_model, 16000)\n",
    "        print('Transcribing...')\n",
    "        res = self.transcribe_words(recognizer, int16)\n",
    "        df = pd.DataFrame.from_records(res)\n",
    "        df = df.sort_values('start')\n",
    "        print('Completed transcribe')\n",
    "        self.df = df\n",
    "        \n",
    "        \n",
    "    def feature_process(self):\n",
    "        # Process by using vosk\n",
    "        self.audioData\n",
    "        df = self.df\n",
    "        model = tf.keras.models.load_model(self.MODEL_PATH)\n",
    "        feature_file = f'{self.FILENAME}_feature.csv'\n",
    "        \n",
    "        sampleRate = self.sampleRate\n",
    "        fail_list = []\n",
    "        time_margin = int( (  (1/self.FRAME_RATE) *self.FRAME_MARGIN ) )\n",
    "        index_margin = int( (  (1/self.FRAME_RATE) *self.FRAME_MARGIN ) *self.sampleRate )\n",
    "\n",
    "        if(os.path.exists(feature_file)):\n",
    "            os.remove(feature_file)\n",
    "\n",
    "        if(not os.path.exists(feature_file)):\n",
    "            print(\"Extracting feature...\")\n",
    "            features = np.empty(shape=(0,80))\n",
    "            ds = Dataset()\n",
    "            for i in tqdm(df.index[:]): \n",
    "                start_index = max(0, int(  df['start'][i] * self.sampleRate))\n",
    "                end_index = min( int( (df['end'][i]) * self.sampleRate), self.audioSampleCount)\n",
    "                fea = ds.get_feature_by_audio(self.audioData[start_index:end_index],11025)\n",
    "                features = np.vstack((features,[fea]))\n",
    "            print(f'Saved features to {feature_file}')\n",
    "            np.savetxt(feature_file, features, delimiter=',')\n",
    "\n",
    "\n",
    "        print(f'Load feature from {feature_file}')\n",
    "        features = np.loadtxt(feature_file,delimiter=',')\n",
    "\n",
    "        print('Predicting...')\n",
    "        predictions = model.predict(x=features, batch_size=84,verbose=0)\n",
    "        print(\"Finish predict!\")\n",
    "\n",
    "        self.predictions = predictions\n",
    "        include_list = []\n",
    "        for i in tqdm(df.index[:]):\n",
    "            isInclude = True\n",
    "            predict = np.round(predictions[i])\n",
    "            word = df['word'][i]\n",
    "            if(word == \"i'm\" or word == 'um' or word =='m' or word=='ah'or word=='huh'or word=='hm'):\n",
    "                if(predict == 1):\n",
    "                    isInclude = False\n",
    "            if(isInclude):\n",
    "                start = df['start'][i]\n",
    "                end = df['end'][i]\n",
    "                ts = Timestamp(start,end,word=word,label=predict)\n",
    "                include_list.append(ts)\n",
    "                \n",
    "        self.include_list = include_list        \n",
    "        render_list = []\n",
    "        counter = 0\n",
    "        start = include_list[0].start\n",
    "        end = include_list[0].end\n",
    "        word = \"\"\n",
    "        for i,ts in tqdm(enumerate(include_list)):\n",
    "            current_start = ts.start\n",
    "            current_end = ts.end\n",
    "            prev_start = include_list[i-1].start\n",
    "            prev_end = include_list[i-1].end\n",
    "            if(i >= 1 and current_start != prev_end):\n",
    "                segment = Timestamp(start,prev_end, word=word)\n",
    "                word = ''\n",
    "                start = current_start\n",
    "                render_list.append(segment)\n",
    "                counter = counter + 1\n",
    "            word = word + ts.word + \" \"    \n",
    "\n",
    "        render_list.append(Timestamp(include_list[-1].start,include_list[-1].end,include_list[-1].word))\n",
    "        self.render_list = render_list           \n",
    "\n",
    "\n",
    "    def generate_complex_filter(self):\n",
    "        render_list = self.render_list\n",
    "        print('Generating complex filter...')\n",
    "        trim = []\n",
    "        duration_list = []\n",
    "        number_of_segment = 0\n",
    "        prev = 0\n",
    "        current = 0\n",
    "        # with out xfade\n",
    "        for ts in render_list:\n",
    "            duration_list.append(ts.end-ts.start)\n",
    "            trim.append(\n",
    "                f'[0:v]trim=start={ts.start}:end={ts.end},setpts=PTS-STARTPTS[v{number_of_segment}]')\n",
    "            trim.append(\n",
    "                f'[0:a]atrim=start={ts.start}:end={ts.end},asetpts=PTS-STARTPTS[a{number_of_segment}]')\n",
    "            number_of_segment += 1\n",
    "\n",
    "        filter = ';'.join(trim)\n",
    "        filter = filter + \";\"\n",
    "\n",
    "        # Normal cut feature\n",
    "        for i in range(number_of_segment):\n",
    "            filter += f' [v{i}] [a{i}]'\n",
    "\n",
    "\n",
    "        # Start to generate ending of command\n",
    "        filter += f'concat=n={number_of_segment}:v=1:a=1 [out]'\n",
    "        filter = '\"' + filter + '\"'\n",
    "        \n",
    "        if(self.isRender):\n",
    "            filter = f'ffmpeg -y -i {self.INPUT_FILE} -filter_complex ' + filter\n",
    "        else:\n",
    "            filter = f'-filter_complex ' + filter\n",
    "\n",
    "        filter = filter + f' -map \"[out]\"'\n",
    "\n",
    "        if(self.isRender):\n",
    "            filter = filter + f' {self.FILENAME}_COMPLEX.mp4'\n",
    "            bat_path = self.write_to_bat(filter)\n",
    "            print('Complete complex filter...')\n",
    "            self.filter = filter\n",
    "        else:\n",
    "            self.filter = filter\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-moisture",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm",
   "language": "python",
   "name": "dm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
